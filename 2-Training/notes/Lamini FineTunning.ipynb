{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technically, it's only a few lines of code to run on GPUs (elsewhere, ie. on Lamini).\n",
    "```\n",
    "from llama import BasicModelRunner\n",
    "\n",
    "model = BasicModelRunner(\"EleutherAI/pythia-410m\") \n",
    "model.load_data_from_jsonlines(\"lamini_docs.jsonl\", input_key=\"question\", output_key=\"answer\")\n",
    "model.train(is_public=True) \n",
    "\n",
    "\n",
    "```\n",
    "1. Choose base model.\n",
    "2. Load data.\n",
    "3. Train it. Returns a model ID, dashboard, and playground interface.\n",
    "\n",
    "### Let's look under the hood at the core code running this! This is the open core of Lamini's `llama` library :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run much larger trained model and explore moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamini\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "lamini.api_key = os.getenv(\"API_KEY\")\n",
    "from llama import BasicModelRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 14:50:12,753 - INFO - lamini.api.inference_queue - Launching 1 batches onto the thread pool of size 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAMINI CONFIGURATION\n",
      "{}\n",
      "LAMINI CONFIGURATION\n",
      "{}\n",
      "LAMINI CONFIGURATION\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "bigger_finetuned_model = BasicModelRunner(model_name_to_id[\"bigger_model_name\"])\n",
    "bigger_finetuned_output = bigger_finetuned_model(test_question)\n",
    "print(\"Bigger (2.8B) finetuned model (test): \", bigger_finetuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(train_dataset)):\n",
    " if \"keep the discussion relevant to Lamini\" in train_dataset[i][\"answer\"]:\n",
    "  print(i, train_dataset[i][\"question\"], train_dataset[i][\"answer\"])\n",
    "  count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune a model in 3 lines of code using Lamini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamini\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "lamini.api_key = os.getenv(\"API_KEY\")\n",
    "from llama import BasicModelRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAMINI CONFIGURATION\n",
      "{}\n",
      "LAMINI CONFIGURATION\n",
      "{}\n",
      "LAMINI CONFIGURATION\n",
      "{}\n",
      "status code: 400\n"
     ]
    },
    {
     "ename": "UserError",
     "evalue": "Please pass either data pairs (eg: llm.train(data=<data>)) or dataset_id (eg: llm.train(dataset_id=<dataset_id>)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Blog\\How-to-Finetuning-Large-Language-Models\\.venv\\lib\\site-packages\\lamini\\api\\rest_requests.py:25\u001b[0m, in \u001b[0;36mmake_web_request\u001b[1;34m(key, url, http_method, json)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Blog\\How-to-Finetuning-Large-Language-Models\\.venv\\lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api.lamini.ai/v1/train",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUserError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m BasicModelRunner(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEleutherAI/pythia-410m\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_data_from_jsonlines(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../lamini_docs.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_public\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \n",
      "File \u001b[1;32mc:\\Blog\\How-to-Finetuning-Large-Language-Models\\.venv\\lib\\site-packages\\lamini\\runners\\base_runner.py:259\u001b[0m, in \u001b[0;36mBaseRunner.train\u001b[1;34m(self, limit, is_public, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     final_status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlamini_api\u001b[38;5;241m.\u001b[39mtrain_and_wait(\n\u001b[0;32m    255\u001b[0m         is_public\u001b[38;5;241m=\u001b[39mis_public,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 259\u001b[0m     final_status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlamini_api\u001b[38;5;241m.\u001b[39mtrain_and_wait(\n\u001b[0;32m    260\u001b[0m         data,\n\u001b[0;32m    261\u001b[0m         is_public\u001b[38;5;241m=\u001b[39mis_public,\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    263\u001b[0m     )\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m final_status[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Blog\\How-to-Finetuning-Large-Language-Models\\.venv\\lib\\site-packages\\lamini\\api\\lamini.py:128\u001b[0m, in \u001b[0;36mLamini.train_and_wait\u001b[1;34m(self, data, finetune_args, enable_peft, peft_args, is_public, use_cached_model, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_wait\u001b[39m(\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    120\u001b[0m     data: Optional[List] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    127\u001b[0m ):\n\u001b[1;32m--> 128\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinetune_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinetune_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_peft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_peft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpeft_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpeft_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_public\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_public\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cached_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cached_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m         status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_job_status(job[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Blog\\How-to-Finetuning-Large-Language-Models\\.venv\\lib\\site-packages\\lamini\\api\\lamini.py:106\u001b[0m, in \u001b[0;36mLamini.train\u001b[1;34m(self, data, finetune_args, enable_peft, peft_args, is_public, use_cached_model)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupload_data(data)\n\u001b[0;32m    104\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinetune_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_peft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeft_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_public\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cached_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Blog\\How-to-Finetuning-Large-Language-Models\\.venv\\lib\\site-packages\\lamini\\api\\train.py:54\u001b[0m, in \u001b[0;36mTrain.train\u001b[1;34m(self, data, model_name, upload_file_path, finetune_args, enable_peft, peft_args, is_public, use_cached_model)\u001b[0m\n\u001b[0;32m     51\u001b[0m     req_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mas_dict()\n\u001b[0;32m     52\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 54\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[43mmake_web_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id \u001b[38;5;241m=\u001b[39m job[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining job submitted! Check status of job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m here: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mui_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m )\n",
      "File \u001b[1;32mc:\\Blog\\How-to-Finetuning-Large-Language-Models\\.venv\\lib\\site-packages\\lamini\\api\\rest_requests.py:53\u001b[0m, in \u001b[0;36mmake_web_request\u001b[1;34m(key, url, http_method, json)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         json_response \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UserError(json_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetail\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUserError\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m422\u001b[39m:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mUserError\u001b[0m: Please pass either data pairs (eg: llm.train(data=<data>)) or dataset_id (eg: llm.train(dataset_id=<dataset_id>))."
     ]
    }
   ],
   "source": [
    "model = BasicModelRunner(\"EleutherAI/pythia-410m\") \n",
    "model.load_data_from_jsonlines(\"../lamini_docs.jsonl\", input_key=\"question\", output_key=\"answer\")\n",
    "model.train(is_public=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BasicModelRunner' object has no attribute 'job_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Blog\\How-to-Finetuning-Large-Language-Models\\.venv\\lib\\site-packages\\lamini\\runners\\base_runner.py:284\u001b[0m, in \u001b[0;36mBaseRunner.evaluate\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n",
      "\u001b[0;32m    283\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get evaluation results\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_id\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m    285\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust train before getting results (no job id))\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlamini_api\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BasicModelRunner' object has no attribute 'job_id'"
     ]
    }
   ],
   "source": [
    "out = model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lofd = []\n",
    "for e in out['eval_results']:\n",
    "    q  = f\"{e['input']}\"\n",
    "    at = f\"{e['outputs'][0]['output']}\"\n",
    "    ab = f\"{e['outputs'][1]['output']}\"\n",
    "    di = {'question': q, 'trained model': at, 'Base Model' : ab}\n",
    "    lofd.append(di)\n",
    "df = pd.DataFrame.from_dict(lofd)\n",
    "style_df = df.style.set_properties(**{'text-align': 'left'})\n",
    "style_df = style_df.set_properties(**{\"vertical-align\": \"text-top\"})\n",
    "style_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
