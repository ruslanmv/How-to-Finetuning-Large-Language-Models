{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import tempfile\n",
    "import logging\n",
    "import random\n",
    "import config\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "from utilities import *\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForCausalLM\n",
    "from llama import BasicModelRunner\n",
    "from transformers.trainer_callback import TrainerCallback\n",
    "import itertools\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9390903fe96e45afa545e78fad437812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Blog\\How-to-Finetuning-Large-Language-Models\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\066226758\\.cache\\huggingface\\hub\\models--EleutherAI--pythia-410m. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90e9d8a5a0540b48d225d6987083d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8988f4928c84c06bbaaf09fbe97b72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 15:24:15,379 - DEBUG - utilities - Config: datasets.path: c:\\Blog\\How-to-Finetuning-Large-Language-Models\\content\\ai-medical-chatbot_processed.jsonl\n",
      "datasets.use_hf: false\n",
      "model.max_length: 2048\n",
      "model.pretrained_name: EleutherAI/pythia-410m\n",
      "verbose: true\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize False c:\\Blog\\How-to-Finetuning-Large-Language-Models\\content\\ai-medical-chatbot_processed.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 15:24:15,814 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-067cad356d1dba73/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/dataset_info.json\n",
      "2024-04-10 15:24:15,909 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-067cad356d1dba73/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/dataset_info.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc511303ad254b0b8216e3c6d4510613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "2024-04-10 15:24:15,952 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-067cad356d1dba73/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/tmpuj4mco1o\n",
      "2024-04-10 15:24:17,273 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-067cad356d1dba73/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/tmpv5b1up9z\n",
      "2024-04-10 15:24:17,289 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-067cad356d1dba73/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/tmpp_8jyaij\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a57ff26db849a4bb195eae4e7dd5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f146133410479997a373bfd92fffe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/911M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 15:26:58,316 - DEBUG - utilities - Select CPU device\n"
     ]
    }
   ],
   "source": [
    "model_name = \"EleutherAI/pythia-410m\"\n",
    "#model_name = \"EleutherAI/pythia-160m\"\n",
    "#model_name = \"EleutherAI/pythia-70m\"\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "# Join the folder path\n",
    "folder_path = os.path.join(current_directory, \"content\")\n",
    "dataset_name = \"ai-medical-chatbot_processed.jsonl\"\n",
    "dataset_path = os.path.join(folder_path, dataset_name)\n",
    "#dataset_path = f\"/content/{dataset_name}\"\n",
    "use_hf = False\n",
    "training_config = {\n",
    "    \"model\": {\n",
    "        \"pretrained_name\": model_name,\n",
    "        \"max_length\" : 2048\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"use_hf\": use_hf,\n",
    "        \"path\": dataset_path\n",
    "    },\n",
    "    \"verbose\": True\n",
    "}\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_dataset, test_dataset = tokenize_and_split_data(training_config, tokenizer)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "device_count = torch.cuda.device_count()\n",
    "if device_count > 0:\n",
    "    logger.debug(\"Select GPU device\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    logger.debug(\"Select CPU device\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def cosine_similarity(str1, str2):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two strings using the Bag-of-Words model.\n",
    "\n",
    "    Args:\n",
    "        str1: The first string.\n",
    "        str2: The second string.\n",
    "\n",
    "    Returns:\n",
    "        A float representing the cosine similarity between the two strings.\n",
    "    \"\"\"\n",
    "    # Tokenize the strings\n",
    "    tokens1 = str1.split()\n",
    "    tokens2 = str2.split()\n",
    "\n",
    "    # Create bag of words for each string\n",
    "    bow1 = Counter(tokens1)\n",
    "    bow2 = Counter(tokens2)\n",
    "\n",
    "    # Get the set of all unique words\n",
    "    all_words = set(bow1.keys()).union(set(bow2.keys()))\n",
    "\n",
    "    # Compute dot product\n",
    "    dot_product = sum(bow1[word] * bow2[word] for word in all_words)\n",
    "\n",
    "    # Compute magnitudes\n",
    "    magnitude1 = math.sqrt(sum(bow1[word] ** 2 for word in all_words))\n",
    "    magnitude2 = math.sqrt(sum(bow2[word] ** 2 for word in all_words))\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return dot_product / (magnitude1 * magnitude2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_new(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=1000):\n",
    "  # Tokenize\n",
    "  input_ids = tokenizer.encode(\n",
    "      text,\n",
    "      return_tensors=\"pt\",\n",
    "      truncation=True,\n",
    "      max_length=max_input_tokens\n",
    "  )\n",
    "\n",
    "  # Generate\n",
    "  device = model.device\n",
    "  attention_mask = torch.ones_like(input_ids)  # Create mask with all 1s\n",
    "\n",
    "  # Fix: Mask all padding tokens, including the first element\n",
    "  attention_mask[input_ids == tokenizer.pad_token_id] = 0\n",
    "\n",
    "  generated_tokens_with_prompt = model.generate(\n",
    "      input_ids.to(device),\n",
    "      max_length=max_output_tokens,\n",
    "      attention_mask=attention_mask,\n",
    "      pad_token_id=tokenizer.eos_token_id  # Set pad token\n",
    "  )\n",
    "\n",
    "  # Decode\n",
    "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "  # Strip the prompt\n",
    "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "  return generated_text_answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import shutil\n",
    "def train_model(hyperparameters, delete=False, testing=False):\n",
    "  max_steps = hyperparameters[\"max_steps\"]\n",
    "\n",
    "\n",
    "  # Convert hyperparameter values to integers and add them to the string\n",
    "  hyperparameter_str = '_'.join(str(int(value)) if isinstance(value, (int, float)) else value for value in hyperparameters.values())\n",
    "  # Create the trained_model_name variable\n",
    "  trained_model_name = f\"ai_medical_{hyperparameter_str}\"\n",
    "\n",
    "  #trained_model_name = f\"ai_medical_{max_steps}_steps\"\n",
    "  output_dir = trained_model_name\n",
    "  training_args = TrainingArguments(\n",
    "    # Learning rate\n",
    "    learning_rate=hyperparameters[\"learning_rate\"],\n",
    "\n",
    "    # Number of training epochs\n",
    "    num_train_epochs=hyperparameters[\"num_train_epochs\"],\n",
    "\n",
    "    # Max steps to train for (each step is a batch of data)\n",
    "    # Overrides num_train_epochs, if not -1\n",
    "    max_steps=max_steps,\n",
    "\n",
    "    # Batch size for training\n",
    "    per_device_train_batch_size=hyperparameters[\"per_device_train_batch_size\"],\n",
    "\n",
    "    # Directory to save model checkpoints\n",
    "    output_dir=output_dir,\n",
    "\n",
    "    # Other arguments\n",
    "    overwrite_output_dir=False, # Overwrite the content of the output directory\n",
    "    disable_tqdm=False, # Disable progress bars\n",
    "    eval_steps=120, # Number of update steps between two evaluations\n",
    "    save_steps=120, # After # steps model is saved\n",
    "    warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
    "    per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    optim=hyperparameters[\"optim\"],\n",
    "    gradient_accumulation_steps = hyperparameters['gradient_accumulation_steps'],\n",
    "    gradient_checkpointing=False,\n",
    "    # Parameters for early stopping\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False\n",
    "  )\n",
    "  base_model.to(device)\n",
    "  model_flops = (\n",
    "    base_model.floating_point_ops(\n",
    "      {\n",
    "        \"input_ids\": torch.zeros(\n",
    "            (1, training_config[\"model\"][\"max_length\"])\n",
    "        )\n",
    "      }\n",
    "    )\n",
    "    * training_args.gradient_accumulation_steps\n",
    "  )\n",
    "\n",
    "  #print(base_model)\n",
    "  print(\"Memory footprint\", base_model.get_memory_footprint() / 1e9, \"GB\")\n",
    "  print(\"Flops\", model_flops / 1e9, \"GFLOPs\")\n",
    "\n",
    "  trainer = Trainer(\n",
    "    model=base_model,\n",
    "    model_flops=model_flops,\n",
    "    total_steps=max_steps,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "  training_output = trainer.train()\n",
    "  # Evaluate the model\n",
    "  eval_results = trainer.evaluate()\n",
    "\n",
    "  # Adding Evaluation \n",
    "  save_dir = f'{output_dir}'\n",
    "  trainer.save_model(save_dir)\n",
    "  print(\"Saved model to:\", save_dir)\n",
    "  finetuned_slightly_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)\n",
    "  finetuned_slightly_model.to(device)\n",
    "  test_question = test_dataset[0]['question']\n",
    "  print(\"Question input (test):\", test_question)\n",
    "  predicted_answer=inference_new(test_question, finetuned_slightly_model, tokenizer)\n",
    "  print(\"Finetuned slightly model's answer: \")\n",
    "  print(predicted_answer) \n",
    "  test_answer = test_dataset[0]['answer']\n",
    "  print(\"Target answer output (test):\", test_answer)\n",
    "  metric_cosine_similarity=cosine_similarity(test_answer, predicted_answer)\n",
    "  print(\"Cosine Similarity:\", metric_cosine_similarity)\n",
    "  # Deleting the folder to save space\n",
    "  clear_output()\n",
    "  if delete:\n",
    "    shutil.rmtree(save_dir)\n",
    "    print(\"Deleted model folder:\", save_dir)\n",
    "  if testing:\n",
    "    return eval_results, training_output, metric_cosine_similarity,test_question,test_answer,predicted_answer\n",
    "\n",
    "  else:\n",
    "    return eval_results, training_output, metric_cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={'learning_rate': 1e-06,\n",
    "'num_train_epochs': 1,\n",
    "'per_device_train_batch_size': 1,\n",
    "'optim': 'adafactor',\n",
    "'num_iterations': 1,\n",
    "'max_steps':3,\n",
    "'gradient_accumulation_steps':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted model folder: ai_medical_0_1_1_adafactor_1_3_2\n"
     ]
    }
   ],
   "source": [
    "eval_results, training_output, metric_cosine_similarity,test_question,test_answer,predicted_answer =train_model(hyperparameters, delete=True, testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n",
      "Correct answer from ai-medical-chatbot: Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Model's answer: \n"
     ]
    }
   ],
   "source": [
    "test_text = test_dataset[0]['question']\n",
    "print(\"Question input (test):\", test_text)\n",
    "print(f\"Correct answer from ai-medical-chatbot: {test_dataset[0]['answer']}\")\n",
    "print(\"Model's answer: \")\n",
    "print(inference_new(test_text, base_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_hyperparameters():\n",
    "    best_hyperparameters = None\n",
    "    best_loss = float('inf')\n",
    "    # Lists to store data\n",
    "    hyperparameters_list = []\n",
    "    eval_results_list = []\n",
    "    training_output_list = []\n",
    "    cosine_similarity_list = []\n",
    "\n",
    "    test_question_list = []\n",
    "    test_answer_list = []\n",
    "    predicted_answer_list = []\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Define hyperparameter search space\n",
    "    hyperparameter_space = {\n",
    "        \"learning_rate\": [6.0e-5, 3.0e-4],\n",
    "        \"num_train_epochs\": [1,5],\n",
    "        \"per_device_train_batch_size\": [1],\n",
    "        \"optim\": [\"adafactor\"],\n",
    "        \"max_steps\": [1,10],\n",
    "        \"gradient_accumulation_steps\": [2],\n",
    "    }\n",
    "\n",
    "    # Generate all combinations of hyperparameters\n",
    "    all_hyperparameters = list(itertools.product(*hyperparameter_space.values()))\n",
    "\n",
    "    # Assuming all_hyperparameters is a list of hyperparameter combinations\n",
    "    for hyperparameter_values in tqdm(all_hyperparameters):\n",
    "        hyperparameters = dict(zip(hyperparameter_space.keys(), hyperparameter_values))\n",
    "        \n",
    "        # Evaluate the model\n",
    "        # Print the current hyperparameters\n",
    "        print(\"Using hyperparameters:\")\n",
    "        for key, value in hyperparameters.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        eval_results, training_output, metric_cosine_similarity, test_question, test_answer, predicted_answer = train_model(hyperparameters,delete=True,testing=True)\n",
    "        \n",
    "        # Append data to lists\n",
    "        hyperparameters_list.append(hyperparameters)\n",
    "        eval_results_list.append(eval_results)\n",
    "        training_output_list.append(training_output)\n",
    "        cosine_similarity_list.append(metric_cosine_similarity)\n",
    "\n",
    "        test_question_list.append(test_question)\n",
    "        test_answer_list.append(test_answer)\n",
    "        predicted_answer_list.append(predicted_answer)\n",
    "\n",
    "        # Check if this set of hyperparameters gives better results\n",
    "        if eval_results[\"eval_loss\"] < best_loss:\n",
    "                best_loss = eval_results[\"eval_loss\"]\n",
    "                best_hyperparameters = hyperparameters\n",
    "        clear_output()\n",
    "    # Create DataFrame\n",
    "    data = {\n",
    "        'Question':test_question_list,\n",
    "        'Answer':test_answer_list,\n",
    "        'Prediction':predicted_answer_list,\n",
    "        'Hyperparameters': hyperparameters_list,\n",
    "        'Evaluation Results': eval_results_list,\n",
    "        'Training Output': training_output_list,\n",
    "        'Cosine Similarity': cosine_similarity_list\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return best_hyperparameters, best_loss, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [17:06<00:00, 128.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# Call the function to find the best hyperparameters\n",
    "best_hyperparameters, best_loss ,df = find_best_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 6e-05, 'num_train_epochs': 1, 'per_device_train_batch_size': 1, 'optim': 'adafactor', 'max_steps': 20, 'gradient_accumulation_steps': 2}\n",
      "Best loss: 2.4853429794311523\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best loss:\", best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'eval_loss' inside the 'Evaluation Results' column\n",
    "df_sorted = df.sort_values(by='Evaluation Results', \n",
    "                           key=lambda x: x.apply(lambda d: d['eval_loss']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Evaluation Results</th>\n",
       "      <th>Training Output</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Will Kalarchikai cure multiple ovarian cysts i...</td>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hi. I have gone through your query and have go...</td>\n",
       "      <td>{'learning_rate': 6e-05, 'num_train_epochs': 1...</td>\n",
       "      <td>{'eval_loss': 2.4853429794311523, 'eval_runtim...</td>\n",
       "      <td>(20, 3.3880001068115235, {'train_runtime': 47....</td>\n",
       "      <td>0.144474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will Kalarchikai cure multiple ovarian cysts i...</td>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hello. I have gone through your query and test...</td>\n",
       "      <td>{'learning_rate': 6e-05, 'num_train_epochs': 5...</td>\n",
       "      <td>{'eval_loss': 2.5364460945129395, 'eval_runtim...</td>\n",
       "      <td>(20, 2.0024101391434668, {'train_runtime': 49....</td>\n",
       "      <td>0.211604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Will Kalarchikai cure multiple ovarian cysts i...</td>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hello. I have gone through your query and test...</td>\n",
       "      <td>{'learning_rate': 6e-05, 'num_train_epochs': 1...</td>\n",
       "      <td>{'eval_loss': 2.7494125366210938, 'eval_runtim...</td>\n",
       "      <td>(20, 1.4947877436876298, {'train_runtime': 47....</td>\n",
       "      <td>0.345688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will Kalarchikai cure multiple ovarian cysts i...</td>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hello. I just read your query. I would like yo...</td>\n",
       "      <td>{'learning_rate': 6e-05, 'num_train_epochs': 2...</td>\n",
       "      <td>{'eval_loss': 3.0984041690826416, 'eval_runtim...</td>\n",
       "      <td>(20, 1.1360332652926446, {'train_runtime': 45....</td>\n",
       "      <td>0.265248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Will Kalarchikai cure multiple ovarian cysts i...</td>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hi. For further information consult a gynecolo...</td>\n",
       "      <td>{'learning_rate': 0.0003, 'num_train_epochs': ...</td>\n",
       "      <td>{'eval_loss': 4.455532073974609, 'eval_runtime...</td>\n",
       "      <td>(20, 5.409056072868407, {'train_runtime': 43.8...</td>\n",
       "      <td>0.233142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Will Kalarchikai cure multiple ovarian cysts i...   \n",
       "1  Will Kalarchikai cure multiple ovarian cysts i...   \n",
       "2  Will Kalarchikai cure multiple ovarian cysts i...   \n",
       "3  Will Kalarchikai cure multiple ovarian cysts i...   \n",
       "4  Will Kalarchikai cure multiple ovarian cysts i...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  Hello. I just read your query. See Kalarachi K...   \n",
       "1  Hello. I just read your query. See Kalarachi K...   \n",
       "2  Hello. I just read your query. See Kalarachi K...   \n",
       "3  Hello. I just read your query. See Kalarachi K...   \n",
       "4  Hello. I just read your query. See Kalarachi K...   \n",
       "\n",
       "                                          Prediction  \\\n",
       "0  Hi. I have gone through your query and have go...   \n",
       "1  Hello. I have gone through your query and test...   \n",
       "2  Hello. I have gone through your query and test...   \n",
       "3  Hello. I just read your query. I would like yo...   \n",
       "4  Hi. For further information consult a gynecolo...   \n",
       "\n",
       "                                     Hyperparameters  \\\n",
       "0  {'learning_rate': 6e-05, 'num_train_epochs': 1...   \n",
       "1  {'learning_rate': 6e-05, 'num_train_epochs': 5...   \n",
       "2  {'learning_rate': 6e-05, 'num_train_epochs': 1...   \n",
       "3  {'learning_rate': 6e-05, 'num_train_epochs': 2...   \n",
       "4  {'learning_rate': 0.0003, 'num_train_epochs': ...   \n",
       "\n",
       "                                  Evaluation Results  \\\n",
       "0  {'eval_loss': 2.4853429794311523, 'eval_runtim...   \n",
       "1  {'eval_loss': 2.5364460945129395, 'eval_runtim...   \n",
       "2  {'eval_loss': 2.7494125366210938, 'eval_runtim...   \n",
       "3  {'eval_loss': 3.0984041690826416, 'eval_runtim...   \n",
       "4  {'eval_loss': 4.455532073974609, 'eval_runtime...   \n",
       "\n",
       "                                     Training Output  Cosine Similarity  \n",
       "0  (20, 3.3880001068115235, {'train_runtime': 47....           0.144474  \n",
       "1  (20, 2.0024101391434668, {'train_runtime': 49....           0.211604  \n",
       "2  (20, 1.4947877436876298, {'train_runtime': 47....           0.345688  \n",
       "3  (20, 1.1360332652926446, {'train_runtime': 45....           0.265248  \n",
       "4  (20, 5.409056072868407, {'train_runtime': 43.8...           0.233142  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hi. I have gone through your query and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and have gone through your queries and'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.head(1)[\"Prediction\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'Cosine Similarity' from largest to smallest\n",
    "df_cos = df.sort_values(by='Cosine Similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Evaluation Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hello. I have gone through your query and test...</td>\n",
       "      <td>0.345688</td>\n",
       "      <td>{'eval_loss': 2.7494125366210938, 'eval_runtim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hello. I just read your query. I would like yo...</td>\n",
       "      <td>0.265248</td>\n",
       "      <td>{'eval_loss': 3.0984041690826416, 'eval_runtim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hi. For further information consult a gynecolo...</td>\n",
       "      <td>0.233142</td>\n",
       "      <td>{'eval_loss': 4.455532073974609, 'eval_runtime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hello. I have gone through your information an...</td>\n",
       "      <td>0.229964</td>\n",
       "      <td>{'eval_loss': 5.980817794799805, 'eval_runtime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hello. I have gone through your query and test...</td>\n",
       "      <td>0.211604</td>\n",
       "      <td>{'eval_loss': 2.5364460945129395, 'eval_runtim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hi. I have gone through your query and have go...</td>\n",
       "      <td>0.144474</td>\n",
       "      <td>{'eval_loss': 2.4853429794311523, 'eval_runtim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hi. I am here to help you. For further informa...</td>\n",
       "      <td>0.107587</td>\n",
       "      <td>{'eval_loss': 5.183531284332275, 'eval_runtime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hello. She would not get ovarian cysts. She wo...</td>\n",
       "      <td>0.075293</td>\n",
       "      <td>{'eval_loss': 6.59088134765625, 'eval_runtime'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Answer  \\\n",
       "2  Hello. I just read your query. See Kalarachi K...   \n",
       "3  Hello. I just read your query. See Kalarachi K...   \n",
       "4  Hello. I just read your query. See Kalarachi K...   \n",
       "6  Hello. I just read your query. See Kalarachi K...   \n",
       "1  Hello. I just read your query. See Kalarachi K...   \n",
       "0  Hello. I just read your query. See Kalarachi K...   \n",
       "5  Hello. I just read your query. See Kalarachi K...   \n",
       "7  Hello. I just read your query. See Kalarachi K...   \n",
       "\n",
       "                                          Prediction  Cosine Similarity  \\\n",
       "2  Hello. I have gone through your query and test...           0.345688   \n",
       "3  Hello. I just read your query. I would like yo...           0.265248   \n",
       "4  Hi. For further information consult a gynecolo...           0.233142   \n",
       "6  Hello. I have gone through your information an...           0.229964   \n",
       "1  Hello. I have gone through your query and test...           0.211604   \n",
       "0  Hi. I have gone through your query and have go...           0.144474   \n",
       "5  Hi. I am here to help you. For further informa...           0.107587   \n",
       "7  Hello. She would not get ovarian cysts. She wo...           0.075293   \n",
       "\n",
       "                                  Evaluation Results  \n",
       "2  {'eval_loss': 2.7494125366210938, 'eval_runtim...  \n",
       "3  {'eval_loss': 3.0984041690826416, 'eval_runtim...  \n",
       "4  {'eval_loss': 4.455532073974609, 'eval_runtime...  \n",
       "6  {'eval_loss': 5.980817794799805, 'eval_runtime...  \n",
       "1  {'eval_loss': 2.5364460945129395, 'eval_runtim...  \n",
       "0  {'eval_loss': 2.4853429794311523, 'eval_runtim...  \n",
       "5  {'eval_loss': 5.183531284332275, 'eval_runtime...  \n",
       "7  {'eval_loss': 6.59088134765625, 'eval_runtime'...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos[[\"Answer\",\"Prediction\",\"Cosine Similarity\",\"Evaluation Results\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
