{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import tempfile\n",
    "import logging\n",
    "import random\n",
    "import config\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "from utilities import *\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForCausalLM\n",
    "from llama import BasicModelRunner\n",
    "from transformers.trainer_callback import TrainerCallback\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 23:29:45,708 - DEBUG - utilities - Config: datasets.path: c:\\Blog\\How-to-Finetuning-Large-Language-Models\\content\\ai-medical-chatbot_processed.jsonl\n",
      "datasets.use_hf: false\n",
      "model.max_length: 2048\n",
      "model.pretrained_name: EleutherAI/pythia-70m\n",
      "verbose: true\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize False c:\\Blog\\How-to-Finetuning-Large-Language-Models\\content\\ai-medical-chatbot_processed.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 23:29:46,097 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-f1c6af33428df321/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/dataset_info.json\n",
      "2024-04-09 23:29:46,128 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-f1c6af33428df321/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/dataset_info.json\n",
      "2024-04-09 23:29:47,276 - DEBUG - utilities - Select CPU device\n"
     ]
    }
   ],
   "source": [
    "model_name = \"EleutherAI/pythia-70m\"\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "# Join the folder path\n",
    "folder_path = os.path.join(current_directory, \"content\")\n",
    "dataset_name = \"ai-medical-chatbot_processed.jsonl\"\n",
    "dataset_path = os.path.join(folder_path, dataset_name)\n",
    "#dataset_path = f\"/content/{dataset_name}\"\n",
    "use_hf = False\n",
    "training_config = {\n",
    "    \"model\": {\n",
    "        \"pretrained_name\": model_name,\n",
    "        \"max_length\" : 2048\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"use_hf\": use_hf,\n",
    "        \"path\": dataset_path\n",
    "    },\n",
    "    \"verbose\": True\n",
    "}\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_dataset, test_dataset = tokenize_and_split_data(training_config, tokenizer)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "device_count = torch.cuda.device_count()\n",
    "if device_count > 0:\n",
    "    logger.debug(\"Select GPU device\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    logger.debug(\"Select CPU device\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def cosine_similarity(str1, str2):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two strings using the Bag-of-Words model.\n",
    "\n",
    "    Args:\n",
    "        str1: The first string.\n",
    "        str2: The second string.\n",
    "\n",
    "    Returns:\n",
    "        A float representing the cosine similarity between the two strings.\n",
    "    \"\"\"\n",
    "    # Tokenize the strings\n",
    "    tokens1 = str1.split()\n",
    "    tokens2 = str2.split()\n",
    "\n",
    "    # Create bag of words for each string\n",
    "    bow1 = Counter(tokens1)\n",
    "    bow2 = Counter(tokens2)\n",
    "\n",
    "    # Get the set of all unique words\n",
    "    all_words = set(bow1.keys()).union(set(bow2.keys()))\n",
    "\n",
    "    # Compute dot product\n",
    "    dot_product = sum(bow1[word] * bow2[word] for word in all_words)\n",
    "\n",
    "    # Compute magnitudes\n",
    "    magnitude1 = math.sqrt(sum(bow1[word] ** 2 for word in all_words))\n",
    "    magnitude2 = math.sqrt(sum(bow2[word] ** 2 for word in all_words))\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return dot_product / (magnitude1 * magnitude2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_new(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=1000):\n",
    "  # Tokenize\n",
    "  input_ids = tokenizer.encode(\n",
    "      text,\n",
    "      return_tensors=\"pt\",\n",
    "      truncation=True,\n",
    "      max_length=max_input_tokens\n",
    "  )\n",
    "\n",
    "  # Generate\n",
    "  device = model.device\n",
    "  attention_mask = torch.ones_like(input_ids)  # Create mask with all 1s\n",
    "\n",
    "  # Fix: Mask all padding tokens, including the first element\n",
    "  attention_mask[input_ids == tokenizer.pad_token_id] = 0\n",
    "\n",
    "  generated_tokens_with_prompt = model.generate(\n",
    "      input_ids.to(device),\n",
    "      max_length=max_output_tokens,\n",
    "      attention_mask=attention_mask,\n",
    "      pad_token_id=tokenizer.eos_token_id  # Set pad token\n",
    "  )\n",
    "\n",
    "  # Decode\n",
    "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "  # Strip the prompt\n",
    "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "  return generated_text_answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import shutil\n",
    "def train_model(hyperparameters, delete=False):\n",
    "  max_steps = hyperparameters[\"max_steps\"]\n",
    "\n",
    "\n",
    "  # Convert hyperparameter values to integers and add them to the string\n",
    "  hyperparameter_str = '_'.join(str(int(value)) if isinstance(value, (int, float)) else value for value in hyperparameters.values())\n",
    "  # Create the trained_model_name variable\n",
    "  trained_model_name = f\"ai_medical_{hyperparameter_str}\"\n",
    "\n",
    "  #trained_model_name = f\"ai_medical_{max_steps}_steps\"\n",
    "  output_dir = trained_model_name\n",
    "  training_args = TrainingArguments(\n",
    "    # Learning rate\n",
    "    learning_rate=hyperparameters[\"learning_rate\"],\n",
    "\n",
    "    # Number of training epochs\n",
    "    num_train_epochs=hyperparameters[\"num_train_epochs\"],\n",
    "\n",
    "    # Max steps to train for (each step is a batch of data)\n",
    "    # Overrides num_train_epochs, if not -1\n",
    "    max_steps=max_steps,\n",
    "\n",
    "    # Batch size for training\n",
    "    per_device_train_batch_size=hyperparameters[\"per_device_train_batch_size\"],\n",
    "\n",
    "    # Directory to save model checkpoints\n",
    "    output_dir=output_dir,\n",
    "\n",
    "    # Other arguments\n",
    "    overwrite_output_dir=False, # Overwrite the content of the output directory\n",
    "    disable_tqdm=False, # Disable progress bars\n",
    "    eval_steps=120, # Number of update steps between two evaluations\n",
    "    save_steps=120, # After # steps model is saved\n",
    "    warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
    "    per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    optim=hyperparameters[\"optim\"],\n",
    "    gradient_accumulation_steps = hyperparameters['gradient_accumulation_steps'],\n",
    "    gradient_checkpointing=False,\n",
    "    # Parameters for early stopping\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False\n",
    "  )\n",
    "  base_model.to(device)\n",
    "  model_flops = (\n",
    "    base_model.floating_point_ops(\n",
    "      {\n",
    "        \"input_ids\": torch.zeros(\n",
    "            (1, training_config[\"model\"][\"max_length\"])\n",
    "        )\n",
    "      }\n",
    "    )\n",
    "    * training_args.gradient_accumulation_steps\n",
    "  )\n",
    "\n",
    "  #print(base_model)\n",
    "  print(\"Memory footprint\", base_model.get_memory_footprint() / 1e9, \"GB\")\n",
    "  print(\"Flops\", model_flops / 1e9, \"GFLOPs\")\n",
    "\n",
    "  trainer = Trainer(\n",
    "    model=base_model,\n",
    "    model_flops=model_flops,\n",
    "    total_steps=max_steps,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "  training_output = trainer.train()\n",
    "  # Evaluate the model\n",
    "  eval_results = trainer.evaluate()\n",
    "\n",
    "  # Adding Evaluation \n",
    "  save_dir = f'{output_dir}'\n",
    "  trainer.save_model(save_dir)\n",
    "  print(\"Saved model to:\", save_dir)\n",
    "  finetuned_slightly_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)\n",
    "  finetuned_slightly_model.to(device)\n",
    "  test_question = test_dataset[0]['question']\n",
    "  print(\"Question input (test):\", test_question)\n",
    "  predicted_answer=inference_new(test_question, finetuned_slightly_model, tokenizer)\n",
    "  print(\"Finetuned slightly model's answer: \")\n",
    "  print(predicted_answer) \n",
    "  test_answer = test_dataset[0]['answer']\n",
    "  print(\"Target answer output (test):\", test_answer)\n",
    "  metric_cosine_similarity=cosine_similarity(test_answer, predicted_answer)\n",
    "  print(\"Cosine Similarity:\", metric_cosine_similarity)\n",
    "  # Deleting the folder to save space\n",
    "  if delete:\n",
    "    shutil.rmtree(save_dir)\n",
    "    print(\"Deleted model folder:\", save_dir)\n",
    "  return eval_results, training_output, metric_cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={'learning_rate': 1e-06,\n",
    "'num_train_epochs': 1,\n",
    "'per_device_train_batch_size': 1,\n",
    "'optim': 'adafactor',\n",
    "'num_iterations': 1,\n",
    "'max_steps':3,\n",
    "'gradient_accumulation_steps':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint 0.30687256 GB\n",
      "Flops 1097.833906176 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71d6e1ae891498abf499d70aa9d4dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:00:08,175 - DEBUG - utilities - Step (1) Logs: {'loss': 4.4618, 'learning_rate': 1e-06, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4618, 'learning_rate': 1e-06, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:00:09,039 - DEBUG - utilities - Step (2) Logs: {'loss': 4.2251, 'learning_rate': 5e-07, 'epoch': 0.0, 'iter_time': 0.863516092300415, 'flops': 1271353152494.6572, 'remaining_time': 0.863516092300415}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2251, 'learning_rate': 5e-07, 'epoch': 0.0, 'iter_time': 0.863516092300415, 'flops': 1271353152494.6572, 'remaining_time': 0.863516092300415}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:00:09,819 - DEBUG - utilities - Step (3) Logs: {'loss': 4.1862, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 0.8219277858734131, 'flops': 1335681704700.3687, 'remaining_time': 0.0}\n",
      "2024-04-10 00:00:09,824 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 2.5603, 'train_samples_per_second': 2.343, 'train_steps_per_second': 1.172, 'total_flos': 91932868608.0, 'train_loss': 4.290998458862305, 'epoch': 0.01, 'iter_time': 0.8244308233261108, 'flops': 1331626468970.2683, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1862, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 0.8219277858734131, 'flops': 1335681704700.3687, 'remaining_time': 0.0}\n",
      "{'train_runtime': 2.5603, 'train_samples_per_second': 2.343, 'train_steps_per_second': 1.172, 'train_loss': 4.290998458862305, 'epoch': 0.01, 'iter_time': 0.8244308233261108, 'flops': 1331626468970.2683, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62b429975f945f09d5de5ee0a8f926c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:00:16,872 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 4.449901580810547, 'eval_runtime': 7.0419, 'eval_samples_per_second': 14.201, 'eval_steps_per_second': 14.201, 'epoch': 0.01, 'iter_time': 4.348652124404907, 'flops': 252453835066.4767, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_1_1_adafactor_1_3_2\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n",
      "Finetuned slightly model's answer: \n",
      "\n",
      "\n",
      "I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.22477887007223482\n",
      "Deleted model folder: ai_medical_0_1_1_adafactor_1_3_2\n"
     ]
    }
   ],
   "source": [
    "eval_results, training_output, metric_cosine_similarity =train_model(hyperparameters, delete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n",
      "Correct answer from ai-medical-chatbot: Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Model's answer: \n"
     ]
    }
   ],
   "source": [
    "test_text = test_dataset[0]['question']\n",
    "print(\"Question input (test):\", test_text)\n",
    "print(f\"Correct answer from ai-medical-chatbot: {test_dataset[0]['answer']}\")\n",
    "print(\"Model's answer: \")\n",
    "#print(inference_new(test_text, base_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_hyperparameters():\n",
    "    best_hyperparameters = None\n",
    "    best_loss = float('inf')\n",
    "    # Lists to store data\n",
    "    hyperparameters_list = []\n",
    "    eval_results_list = []\n",
    "    training_output_list = []\n",
    "    cosine_similarity_list = []\n",
    "    \n",
    "    # Define hyperparameter search space\n",
    "    hyperparameter_space = {\n",
    "        \"learning_rate\": [1e-6, 1e-5, 1e-4],\n",
    "        \"num_train_epochs\": [1,5,10,20],\n",
    "        \"per_device_train_batch_size\": [1],\n",
    "        \"optim\": [\"adafactor\"],\n",
    "        \"num_iterations\": [1],\n",
    "        \"max_steps\": [3],\n",
    "        \"gradient_accumulation_steps\": [3],\n",
    "    }\n",
    "    # Generate all combinations of hyperparameters\n",
    "    all_hyperparameters = list(itertools.product(*hyperparameter_space.values()))\n",
    "\n",
    "    # Assuming all_hyperparameters is a list of hyperparameter combinations\n",
    "    for hyperparameter_values in tqdm(all_hyperparameters):\n",
    "        hyperparameters = dict(zip(hyperparameter_space.keys(), hyperparameter_values))\n",
    "        \n",
    "        # Evaluate the model\n",
    "        # Print the current hyperparameters\n",
    "        print(\"Using hyperparameters:\")\n",
    "        for key, value in hyperparameters.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        eval_results, training_output, metric_cosine_similarity = train_model(hyperparameters,delete=True)\n",
    "        \n",
    "        # Append data to lists\n",
    "        hyperparameters_list.append(hyperparameters)\n",
    "        eval_results_list.append(eval_results)\n",
    "        training_output_list.append(training_output)\n",
    "        cosine_similarity_list.append(metric_cosine_similarity)\n",
    "\n",
    "        # Check if this set of hyperparameters gives better results\n",
    "        if eval_results[\"eval_loss\"] < best_loss:\n",
    "                best_loss = eval_results[\"eval_loss\"]\n",
    "                best_hyperparameters = hyperparameters\n",
    "\n",
    "    # Create DataFrame\n",
    "    data = {\n",
    "        'Hyperparameters': hyperparameters_list,\n",
    "        'Evaluation Results': eval_results_list,\n",
    "        'Training Output': training_output_list,\n",
    "        'Cosine Similarity': cosine_similarity_list\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return best_hyperparameters, best_loss, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using hyperparameters:\n",
      "learning_rate: 1e-06\n",
      "num_train_epochs: 1\n",
      "per_device_train_batch_size: 1\n",
      "optim: adafactor\n",
      "num_iterations: 1\n",
      "max_steps: 3\n",
      "gradient_accumulation_steps: 3\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 1646.750859264 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9f1be7eeca4ebc81f759352edca03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:08:29,201 - DEBUG - utilities - Step (1) Logs: {'loss': 4.3719, 'learning_rate': 1e-06, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      "  0%|          | 0/12 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3719, 'learning_rate': 1e-06, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:08:30,267 - DEBUG - utilities - Step (2) Logs: {'loss': 4.0918, 'learning_rate': 5e-07, 'epoch': 0.01, 'iter_time': 1.0710382461547852, 'flops': 1537527595467.4111, 'remaining_time': 1.0710382461547852}\n",
      "  0%|          | 0/12 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0918, 'learning_rate': 5e-07, 'epoch': 0.01, 'iter_time': 1.0710382461547852, 'flops': 1537527595467.4111, 'remaining_time': 1.0710382461547852}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:08:31,300 - DEBUG - utilities - Step (3) Logs: {'loss': 4.0965, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0521172285079956, 'flops': 1565178113848.8271, 'remaining_time': 0.0}\n",
      "  0%|          | 0/12 [00:03<?, ?it/s]2024-04-10 00:08:31,307 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 3.2412, 'train_samples_per_second': 2.777, 'train_steps_per_second': 0.926, 'total_flos': 138837393408.0, 'train_loss': 4.1867062250773115, 'epoch': 0.01, 'iter_time': 1.0559263229370117, 'flops': 1559531970643.2134, 'remaining_time': 0.0}\n",
      "  0%|          | 0/12 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0965, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0521172285079956, 'flops': 1565178113848.8271, 'remaining_time': 0.0}\n",
      "{'train_runtime': 3.2412, 'train_samples_per_second': 2.777, 'train_steps_per_second': 0.926, 'train_loss': 4.1867062250773115, 'epoch': 0.01, 'iter_time': 1.0559263229370117, 'flops': 1559531970643.2134, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4161c21f87b04aa29b4f8d51bd4fdff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:08:37,815 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 4.424636363983154, 'eval_runtime': 6.4975, 'eval_samples_per_second': 15.39, 'eval_steps_per_second': 15.39, 'epoch': 0.01, 'iter_time': 4.309926867485046, 'flops': 382083248717.6103, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_1_1_adafactor_1_3_3\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:28<05:11, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned slightly model's answer: \n",
      "\n",
      "\n",
      "I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.22477887007223482\n",
      "Deleted model folder: ai_medical_0_1_1_adafactor_1_3_3\n",
      "Using hyperparameters:\n",
      "learning_rate: 1e-06\n",
      "num_train_epochs: 5\n",
      "per_device_train_batch_size: 1\n",
      "optim: adafactor\n",
      "num_iterations: 1\n",
      "max_steps: 3\n",
      "gradient_accumulation_steps: 3\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 1646.750859264 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab639003eb614340abfdf9e0f70413ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:08:57,277 - DEBUG - utilities - Step (1) Logs: {'loss': 4.3166, 'learning_rate': 1e-06, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      "  8%|▊         | 1/12 [00:29<05:11, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3166, 'learning_rate': 1e-06, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:08:58,294 - DEBUG - utilities - Step (2) Logs: {'loss': 4.0109, 'learning_rate': 5e-07, 'epoch': 0.01, 'iter_time': 1.0172693729400635, 'flops': 1618795279862.4412, 'remaining_time': 1.0172693729400635}\n",
      "  8%|▊         | 1/12 [00:30<05:11, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0109, 'learning_rate': 5e-07, 'epoch': 0.01, 'iter_time': 1.0172693729400635, 'flops': 1618795279862.4412, 'remaining_time': 1.0172693729400635}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:08:59,227 - DEBUG - utilities - Step (3) Logs: {'loss': 4.0395, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 0.9747419357299805, 'flops': 1689422398791.8962, 'remaining_time': 0.0}\n",
      "  8%|▊         | 1/12 [00:31<05:11, 28.34s/it]2024-04-10 00:08:59,230 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 2.9149, 'train_samples_per_second': 3.088, 'train_steps_per_second': 1.029, 'total_flos': 138837393408.0, 'train_loss': 4.1223320960998535, 'epoch': 0.01, 'iter_time': 0.976625919342041, 'flops': 1686163378065.3972, 'remaining_time': 0.0}\n",
      "  8%|▊         | 1/12 [00:31<05:11, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0395, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 0.9747419357299805, 'flops': 1689422398791.8962, 'remaining_time': 0.0}\n",
      "{'train_runtime': 2.9149, 'train_samples_per_second': 3.088, 'train_steps_per_second': 1.029, 'train_loss': 4.1223320960998535, 'epoch': 0.01, 'iter_time': 0.976625919342041, 'flops': 1686163378065.3972, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f767eaf3ca47ed83e1d8056934f91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:09:06,365 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 4.399848461151123, 'eval_runtime': 7.123, 'eval_samples_per_second': 14.039, 'eval_steps_per_second': 14.039, 'epoch': 0.01, 'iter_time': 4.543645262718201, 'flops': 362429451254.92566, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_5_1_adafactor_1_3_3\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:56<04:42, 28.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned slightly model's answer: \n",
      "\n",
      "\n",
      "I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.22477887007223482\n",
      "Deleted model folder: ai_medical_0_5_1_adafactor_1_3_3\n",
      "Using hyperparameters:\n",
      "learning_rate: 1e-06\n",
      "num_train_epochs: 10\n",
      "per_device_train_batch_size: 1\n",
      "optim: adafactor\n",
      "num_iterations: 1\n",
      "max_steps: 3\n",
      "gradient_accumulation_steps: 3\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 1646.750859264 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ae5968f36941e0860de8f6fb64c387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:09:25,430 - DEBUG - utilities - Step (1) Logs: {'loss': 4.2632, 'learning_rate': 1e-06, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      " 17%|█▋        | 2/12 [00:57<04:42, 28.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2632, 'learning_rate': 1e-06, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:09:26,434 - DEBUG - utilities - Step (2) Logs: {'loss': 3.9311, 'learning_rate': 5e-07, 'epoch': 0.01, 'iter_time': 1.0041427612304688, 'flops': 1639956909360.263, 'remaining_time': 1.0041427612304688}\n",
      " 17%|█▋        | 2/12 [00:58<04:42, 28.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9311, 'learning_rate': 5e-07, 'epoch': 0.01, 'iter_time': 1.0041427612304688, 'flops': 1639956909360.263, 'remaining_time': 1.0041427612304688}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:09:27,440 - DEBUG - utilities - Step (3) Logs: {'loss': 3.9849, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0054903030395508, 'flops': 1637759065687.6035, 'remaining_time': 0.0}\n",
      " 17%|█▋        | 2/12 [00:59<04:42, 28.25s/it]2024-04-10 00:09:27,448 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 2.9288, 'train_samples_per_second': 3.073, 'train_steps_per_second': 1.024, 'total_flos': 138837393408.0, 'train_loss': 4.059745152791341, 'epoch': 0.01, 'iter_time': 1.009279727935791, 'flops': 1631609962712.7, 'remaining_time': 0.0}\n",
      " 17%|█▋        | 2/12 [00:59<04:42, 28.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9849, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0054903030395508, 'flops': 1637759065687.6035, 'remaining_time': 0.0}\n",
      "{'train_runtime': 2.9288, 'train_samples_per_second': 3.073, 'train_steps_per_second': 1.024, 'train_loss': 4.059745152791341, 'epoch': 0.01, 'iter_time': 1.009279727935791, 'flops': 1631609962712.7, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afc4690fc22488a9c72d56f02dbd731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:09:34,240 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 4.3765645027160645, 'eval_runtime': 6.7848, 'eval_samples_per_second': 14.739, 'eval_steps_per_second': 14.739, 'epoch': 0.01, 'iter_time': 4.4053168296813965, 'flops': 373809858162.48254, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_10_1_adafactor_1_3_3\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [01:24<04:12, 28.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned slightly model's answer: \n",
      "\n",
      "\n",
      "I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very long list of cases. I have a very\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.22477887007223482\n",
      "Deleted model folder: ai_medical_0_10_1_adafactor_1_3_3\n",
      "Using hyperparameters:\n",
      "learning_rate: 1e-06\n",
      "num_train_epochs: 20\n",
      "per_device_train_batch_size: 1\n",
      "optim: adafactor\n",
      "num_iterations: 1\n",
      "max_steps: 3\n",
      "gradient_accumulation_steps: 3\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 1646.750859264 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7b37347f43438caa5cbd18bb06bfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:09:53,239 - DEBUG - utilities - Step (1) Logs: {'loss': 4.2132, 'learning_rate': 1e-06, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      " 25%|██▌       | 3/12 [01:25<04:12, 28.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2132, 'learning_rate': 1e-06, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:09:54,259 - DEBUG - utilities - Step (2) Logs: {'loss': 3.8522, 'learning_rate': 5e-07, 'epoch': 0.01, 'iter_time': 1.0203006267547607, 'flops': 1613985933245.744, 'remaining_time': 1.0203006267547607}\n",
      " 25%|██▌       | 3/12 [01:26<04:12, 28.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8522, 'learning_rate': 5e-07, 'epoch': 0.01, 'iter_time': 1.0203006267547607, 'flops': 1613985933245.744, 'remaining_time': 1.0203006267547607}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:09:55,179 - DEBUG - utilities - Step (3) Logs: {'loss': 3.934, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 0.9700396060943604, 'flops': 1697611982972.799, 'remaining_time': 0.0}\n",
      " 25%|██▌       | 3/12 [01:27<04:12, 28.02s/it]2024-04-10 00:09:55,185 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 2.9441, 'train_samples_per_second': 3.057, 'train_steps_per_second': 1.019, 'total_flos': 138837393408.0, 'train_loss': 3.999807039896647, 'epoch': 0.01, 'iter_time': 0.9726808071136475, 'flops': 1693002316094.4253, 'remaining_time': 0.0}\n",
      " 25%|██▌       | 3/12 [01:27<04:12, 28.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.934, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 0.9700396060943604, 'flops': 1697611982972.799, 'remaining_time': 0.0}\n",
      "{'train_runtime': 2.9441, 'train_samples_per_second': 3.057, 'train_steps_per_second': 1.019, 'train_loss': 3.999807039896647, 'epoch': 0.01, 'iter_time': 0.9726808071136475, 'flops': 1693002316094.4253, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af10f5ba7b874a95adcb813615e7d590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:10:02,433 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 4.3534440994262695, 'eval_runtime': 7.2422, 'eval_samples_per_second': 13.808, 'eval_steps_per_second': 13.808, 'epoch': 0.01, 'iter_time': 4.597127795219421, 'flops': 358212982675.0662, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_20_1_adafactor_1_3_3\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [01:55<03:53, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned slightly model's answer: \n",
      "\n",
      "\n",
      "I have a very good idea to try this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a lot of experience with this. I have a\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.22582838795743423\n",
      "Deleted model folder: ai_medical_0_20_1_adafactor_1_3_3\n",
      "Using hyperparameters:\n",
      "learning_rate: 1e-05\n",
      "num_train_epochs: 1\n",
      "per_device_train_batch_size: 1\n",
      "optim: adafactor\n",
      "num_iterations: 1\n",
      "max_steps: 3\n",
      "gradient_accumulation_steps: 3\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 1646.750859264 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c5f862a70e4453945753ad34969243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:10:24,279 - DEBUG - utilities - Step (1) Logs: {'loss': 4.1645, 'learning_rate': 1e-05, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      " 33%|███▎      | 4/12 [01:56<03:53, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1645, 'learning_rate': 1e-05, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:10:25,479 - DEBUG - utilities - Step (2) Logs: {'loss': 3.7741, 'learning_rate': 5e-06, 'epoch': 0.01, 'iter_time': 1.1997606754302979, 'flops': 1372566123384.0554, 'remaining_time': 1.1997606754302979}\n",
      " 33%|███▎      | 4/12 [01:57<03:53, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7741, 'learning_rate': 5e-06, 'epoch': 0.01, 'iter_time': 1.1997606754302979, 'flops': 1372566123384.0554, 'remaining_time': 1.1997606754302979}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:10:26,489 - DEBUG - utilities - Step (3) Logs: {'loss': 3.7762, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.104989767074585, 'flops': 1490286071719.6553, 'remaining_time': 0.0}\n",
      " 33%|███▎      | 4/12 [01:58<03:53, 29.13s/it]2024-04-10 00:10:26,497 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 3.3779, 'train_samples_per_second': 2.664, 'train_steps_per_second': 0.888, 'total_flos': 138837393408.0, 'train_loss': 3.904948075612386, 'epoch': 0.01, 'iter_time': 1.108798623085022, 'flops': 1485166760653.2808, 'remaining_time': 0.0}\n",
      " 33%|███▎      | 4/12 [01:58<03:53, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7762, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.104989767074585, 'flops': 1490286071719.6553, 'remaining_time': 0.0}\n",
      "{'train_runtime': 3.3779, 'train_samples_per_second': 2.664, 'train_steps_per_second': 0.888, 'train_loss': 3.904948075612386, 'epoch': 0.01, 'iter_time': 1.108798623085022, 'flops': 1485166760653.2808, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb61721b70964cb48eeda58dd24f0f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:10:34,341 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 4.159300804138184, 'eval_runtime': 7.8343, 'eval_samples_per_second': 12.764, 'eval_steps_per_second': 12.764, 'epoch': 0.01, 'iter_time': 5.030766725540161, 'flops': 327335960720.21924, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_1_1_adafactor_1_3_3\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [02:27<03:31, 30.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned slightly model's answer: \n",
      "\n",
      "\n",
      "A:\n",
      "\n",
      "I think you should use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a \"do not use a\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.1423290973474366\n",
      "Deleted model folder: ai_medical_0_1_1_adafactor_1_3_3\n",
      "Using hyperparameters:\n",
      "learning_rate: 1e-05\n",
      "num_train_epochs: 5\n",
      "per_device_train_batch_size: 1\n",
      "optim: adafactor\n",
      "num_iterations: 1\n",
      "max_steps: 3\n",
      "gradient_accumulation_steps: 3\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 1646.750859264 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99e1b4f77714cca825496e99c4984e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:10:56,419 - DEBUG - utilities - Step (1) Logs: {'loss': 3.7539, 'learning_rate': 1e-05, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      " 42%|████▏     | 5/12 [02:28<03:31, 30.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7539, 'learning_rate': 1e-05, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:10:57,454 - DEBUG - utilities - Step (2) Logs: {'loss': 3.0897, 'learning_rate': 5e-06, 'epoch': 0.01, 'iter_time': 1.0353007316589355, 'flops': 1590601463813.6057, 'remaining_time': 1.0353007316589355}\n",
      " 42%|████▏     | 5/12 [02:29<03:31, 30.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0897, 'learning_rate': 5e-06, 'epoch': 0.01, 'iter_time': 1.0353007316589355, 'flops': 1590601463813.6057, 'remaining_time': 1.0353007316589355}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:10:58,447 - DEBUG - utilities - Step (3) Logs: {'loss': 3.3709, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0138052701950073, 'flops': 1624326591779.548, 'remaining_time': 0.0}\n",
      " 42%|████▏     | 5/12 [02:30<03:31, 30.27s/it]2024-04-10 00:10:58,451 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 3.0225, 'train_samples_per_second': 2.978, 'train_steps_per_second': 0.993, 'total_flos': 138837393408.0, 'train_loss': 3.4048125743865967, 'epoch': 0.01, 'iter_time': 1.016201138496399, 'flops': 1620496963524.9385, 'remaining_time': 0.0}\n",
      " 42%|████▏     | 5/12 [02:30<03:31, 30.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3709, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0138052701950073, 'flops': 1624326591779.548, 'remaining_time': 0.0}\n",
      "{'train_runtime': 3.0225, 'train_samples_per_second': 2.978, 'train_steps_per_second': 0.993, 'train_loss': 3.4048125743865967, 'epoch': 0.01, 'iter_time': 1.016201138496399, 'flops': 1620496963524.9385, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c734d00a274329af4f07ecc3fb81ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:11:06,080 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 3.987677574157715, 'eval_runtime': 7.6198, 'eval_samples_per_second': 13.124, 'eval_steps_per_second': 13.124, 'epoch': 0.01, 'iter_time': 4.830623984336853, 'flops': 340898166490.1963, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_5_1_adafactor_1_3_3\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [02:56<02:59, 29.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned slightly model's answer: \n",
      "\n",
      "\n",
      "A:\n",
      "\n",
      "I think you should consult a doctor for a complete medical history.  If you have a history of ovarian cyst, then you should consult a doctor for a complete medical history.  If you have a history of ovarian cyst, then consult a doctor for a complete medical history.  If you have a history of ovarian cyst, then consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor for a complete medical history.  If you have a history of ovarian cyst, consult a doctor\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.27276661262085156\n",
      "Deleted model folder: ai_medical_0_5_1_adafactor_1_3_3\n",
      "Using hyperparameters:\n",
      "learning_rate: 1e-05\n",
      "num_train_epochs: 10\n",
      "per_device_train_batch_size: 1\n",
      "optim: adafactor\n",
      "num_iterations: 1\n",
      "max_steps: 3\n",
      "gradient_accumulation_steps: 3\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 1646.750859264 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8bc33077144016923fc32a0111ee61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:11:25,484 - DEBUG - utilities - Step (1) Logs: {'loss': 3.369, 'learning_rate': 1e-05, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      " 50%|█████     | 6/12 [02:57<02:59, 29.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.369, 'learning_rate': 1e-05, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:11:26,584 - DEBUG - utilities - Step (2) Logs: {'loss': 2.4756, 'learning_rate': 5e-06, 'epoch': 0.01, 'iter_time': 1.1001179218292236, 'flops': 1496885767051.1006, 'remaining_time': 1.1001179218292236}\n",
      " 50%|█████     | 6/12 [02:58<02:59, 29.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4756, 'learning_rate': 5e-06, 'epoch': 0.01, 'iter_time': 1.1001179218292236, 'flops': 1496885767051.1006, 'remaining_time': 1.1001179218292236}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:11:27,654 - DEBUG - utilities - Step (3) Logs: {'loss': 2.9866, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0849488973617554, 'flops': 1517814215276.282, 'remaining_time': 0.0}\n",
      " 50%|█████     | 6/12 [02:59<02:59, 29.86s/it]2024-04-10 00:11:27,658 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 3.1788, 'train_samples_per_second': 2.831, 'train_steps_per_second': 0.944, 'total_flos': 138837393408.0, 'train_loss': 2.943731149037679, 'epoch': 0.01, 'iter_time': 1.0869437456130981, 'flops': 1515028598223.4883, 'remaining_time': 0.0}\n",
      " 50%|█████     | 6/12 [02:59<02:59, 29.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9866, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0849488973617554, 'flops': 1517814215276.282, 'remaining_time': 0.0}\n",
      "{'train_runtime': 3.1788, 'train_samples_per_second': 2.831, 'train_steps_per_second': 0.944, 'train_loss': 2.943731149037679, 'epoch': 0.01, 'iter_time': 1.0869437456130981, 'flops': 1515028598223.4883, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b392e7fb45ae45398aa284d1bf520962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:11:35,239 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 3.842315673828125, 'eval_runtime': 7.5717, 'eval_samples_per_second': 13.207, 'eval_steps_per_second': 13.207, 'epoch': 0.01, 'iter_time': 4.877526760101318, 'flops': 337620056282.33453, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_10_1_adafactor_1_3_3\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [03:25<02:28, 29.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned slightly model's answer: \n",
      "\n",
      "\n",
      "Hi, I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.20207954409658194\n",
      "Deleted model folder: ai_medical_0_10_1_adafactor_1_3_3\n",
      "Using hyperparameters:\n",
      "learning_rate: 1e-05\n",
      "num_train_epochs: 20\n",
      "per_device_train_batch_size: 1\n",
      "optim: adafactor\n",
      "num_iterations: 1\n",
      "max_steps: 3\n",
      "gradient_accumulation_steps: 3\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 1646.750859264 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1109abd6f9be4187b997bbb27be6497b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:11:54,639 - DEBUG - utilities - Step (1) Logs: {'loss': 2.9971, 'learning_rate': 1e-05, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      " 58%|█████▊    | 7/12 [03:26<02:28, 29.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9971, 'learning_rate': 1e-05, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:11:55,707 - DEBUG - utilities - Step (2) Logs: {'loss': 1.9608, 'learning_rate': 5e-06, 'epoch': 0.01, 'iter_time': 1.0677645206451416, 'flops': 1542241596741.7944, 'remaining_time': 1.0677645206451416}\n",
      " 58%|█████▊    | 7/12 [03:27<02:28, 29.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9608, 'learning_rate': 5e-06, 'epoch': 0.01, 'iter_time': 1.0677645206451416, 'flops': 1542241596741.7944, 'remaining_time': 1.0677645206451416}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:11:56,699 - DEBUG - utilities - Step (3) Logs: {'loss': 2.6696, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0300534963607788, 'flops': 1598704208162.0403, 'remaining_time': 0.0}\n",
      " 58%|█████▊    | 7/12 [03:28<02:28, 29.64s/it]2024-04-10 00:11:56,705 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 3.0564, 'train_samples_per_second': 2.945, 'train_steps_per_second': 0.982, 'total_flos': 138837393408.0, 'train_loss': 2.542485992113749, 'epoch': 0.01, 'iter_time': 1.0330538749694824, 'flops': 1594060967355.3054, 'remaining_time': 0.0}\n",
      " 58%|█████▊    | 7/12 [03:28<02:28, 29.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6696, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0300534963607788, 'flops': 1598704208162.0403, 'remaining_time': 0.0}\n",
      "{'train_runtime': 3.0564, 'train_samples_per_second': 2.945, 'train_steps_per_second': 0.982, 'train_loss': 2.542485992113749, 'epoch': 0.01, 'iter_time': 1.0330538749694824, 'flops': 1594060967355.3054, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c5458287e842fc926e873742c0af5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:12:04,184 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 3.747753620147705, 'eval_runtime': 7.4692, 'eval_samples_per_second': 13.388, 'eval_steps_per_second': 13.388, 'epoch': 0.01, 'iter_time': 4.772409200668335, 'flops': 345056509201.5552, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_20_1_adafactor_1_3_3\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [03:54<01:57, 29.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned slightly model's answer: \n",
      "\n",
      "\n",
      "Hi. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a question for you. I have a\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.20207954409658194\n",
      "Deleted model folder: ai_medical_0_20_1_adafactor_1_3_3\n",
      "Using hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "num_train_epochs: 1\n",
      "per_device_train_batch_size: 1\n",
      "optim: adafactor\n",
      "num_iterations: 1\n",
      "max_steps: 3\n",
      "gradient_accumulation_steps: 3\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 1646.750859264 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e80a1992a849b5993c5b8ba76331c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:12:23,461 - DEBUG - utilities - Step (1) Logs: {'loss': 2.7182, 'learning_rate': 0.0001, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      " 67%|██████▋   | 8/12 [03:55<01:57, 29.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7182, 'learning_rate': 0.0001, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:12:24,520 - DEBUG - utilities - Step (2) Logs: {'loss': 1.5383, 'learning_rate': 5e-05, 'epoch': 0.01, 'iter_time': 1.059624433517456, 'flops': 1554089172705.8044, 'remaining_time': 1.059624433517456}\n",
      " 67%|██████▋   | 8/12 [03:56<01:57, 29.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5383, 'learning_rate': 5e-05, 'epoch': 0.01, 'iter_time': 1.059624433517456, 'flops': 1554089172705.8044, 'remaining_time': 1.059624433517456}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:12:25,594 - DEBUG - utilities - Step (3) Logs: {'loss': 3.9501, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0665181875228882, 'flops': 1544043860225.9275, 'remaining_time': 0.0}\n",
      " 67%|██████▋   | 8/12 [03:57<01:57, 29.38s/it]2024-04-10 00:12:25,601 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 3.0976, 'train_samples_per_second': 2.905, 'train_steps_per_second': 0.968, 'total_flos': 138837393408.0, 'train_loss': 2.735529979070028, 'epoch': 0.01, 'iter_time': 1.069452166557312, 'flops': 1539807866830.6204, 'remaining_time': 0.0}\n",
      " 67%|██████▋   | 8/12 [03:57<01:57, 29.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9501, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0665181875228882, 'flops': 1544043860225.9275, 'remaining_time': 0.0}\n",
      "{'train_runtime': 3.0976, 'train_samples_per_second': 2.905, 'train_steps_per_second': 0.968, 'train_loss': 2.735529979070028, 'epoch': 0.01, 'iter_time': 1.069452166557312, 'flops': 1539807866830.6204, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce68ef3875154a5b908c9aea57a9e2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:12:33,028 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 3.955519914627075, 'eval_runtime': 7.4187, 'eval_samples_per_second': 13.48, 'eval_steps_per_second': 13.48, 'epoch': 0.01, 'iter_time': 4.7835365533828735, 'flops': 344253846685.76074, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_1_1_adafactor_1_3_3\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [04:23<01:27, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned slightly model's answer: \n",
      "Hi. For further information consult a urologist online --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist --> urologist\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.0008159329659100384\n",
      "Deleted model folder: ai_medical_0_1_1_adafactor_1_3_3\n",
      "Using hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "num_train_epochs: 5\n",
      "per_device_train_batch_size: 1\n",
      "optim: adafactor\n",
      "num_iterations: 1\n",
      "max_steps: 3\n",
      "gradient_accumulation_steps: 3\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 1646.750859264 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4ebab66a8b4f4591ccf4457e090f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:12:52,439 - DEBUG - utilities - Step (1) Logs: {'loss': 2.1435, 'learning_rate': 0.0001, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      " 75%|███████▌  | 9/12 [04:24<01:27, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1435, 'learning_rate': 0.0001, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:12:53,469 - DEBUG - utilities - Step (2) Logs: {'loss': 0.4897, 'learning_rate': 5e-05, 'epoch': 0.01, 'iter_time': 1.0297749042510986, 'flops': 1599136716641.5808, 'remaining_time': 1.0297749042510986}\n",
      " 75%|███████▌  | 9/12 [04:25<01:27, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4897, 'learning_rate': 5e-05, 'epoch': 0.01, 'iter_time': 1.0297749042510986, 'flops': 1599136716641.5808, 'remaining_time': 1.0297749042510986}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:12:54,454 - DEBUG - utilities - Step (3) Logs: {'loss': 2.7209, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0074119567871094, 'flops': 1634635015168.8726, 'remaining_time': 0.0}\n",
      " 75%|███████▌  | 9/12 [04:26<01:27, 29.21s/it]2024-04-10 00:12:54,458 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 3.1437, 'train_samples_per_second': 2.863, 'train_steps_per_second': 0.954, 'total_flos': 138837393408.0, 'train_loss': 1.7846872011820476, 'epoch': 0.01, 'iter_time': 1.009319543838501, 'flops': 1631545598533.9495, 'remaining_time': 0.0}\n",
      " 75%|███████▌  | 9/12 [04:26<01:27, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7209, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.0074119567871094, 'flops': 1634635015168.8726, 'remaining_time': 0.0}\n",
      "{'train_runtime': 3.1437, 'train_samples_per_second': 2.863, 'train_steps_per_second': 0.954, 'train_loss': 1.7846872011820476, 'epoch': 0.01, 'iter_time': 1.009319543838501, 'flops': 1631545598533.9495, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec19cb4bd21645b6a815eaa1bcb96f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:13:01,962 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 4.3177995681762695, 'eval_runtime': 7.4951, 'eval_samples_per_second': 13.342, 'eval_steps_per_second': 13.342, 'epoch': 0.01, 'iter_time': 4.761642575263977, 'flops': 345836721936.8008, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_5_1_adafactor_1_3_3\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [04:52<00:58, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned slightly model's answer: \n",
      "Hi. Is it a steroid?Hi. I have gone through your information and test reports and reports. For more information consult a urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> u\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.003605239042848693\n",
      "Deleted model folder: ai_medical_0_5_1_adafactor_1_3_3\n",
      "Using hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "num_train_epochs: 10\n",
      "per_device_train_batch_size: 1\n",
      "optim: adafactor\n",
      "num_iterations: 1\n",
      "max_steps: 3\n",
      "gradient_accumulation_steps: 3\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 1646.750859264 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f544775a084caf86ecc859ecdda71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:13:21,250 - DEBUG - utilities - Step (1) Logs: {'loss': 2.1096, 'learning_rate': 0.0001, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      " 83%|████████▎ | 10/12 [04:53<00:58, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1096, 'learning_rate': 0.0001, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:13:22,338 - DEBUG - utilities - Step (2) Logs: {'loss': 0.351, 'learning_rate': 5e-05, 'epoch': 0.01, 'iter_time': 1.0882236957550049, 'flops': 1513246647438.1367, 'remaining_time': 1.0882236957550049}\n",
      " 83%|████████▎ | 10/12 [04:54<00:58, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.351, 'learning_rate': 5e-05, 'epoch': 0.01, 'iter_time': 1.0882236957550049, 'flops': 1513246647438.1367, 'remaining_time': 1.0882236957550049}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:13:23,297 - DEBUG - utilities - Step (3) Logs: {'loss': 2.2364, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.023516058921814, 'flops': 1608915507391.9507, 'remaining_time': 0.0}\n",
      " 83%|████████▎ | 10/12 [04:55<00:58, 29.13s/it]2024-04-10 00:13:23,301 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 3.0576, 'train_samples_per_second': 2.943, 'train_steps_per_second': 0.981, 'total_flos': 138837393408.0, 'train_loss': 1.5656781792640686, 'epoch': 0.01, 'iter_time': 1.025452971458435, 'flops': 1605876529785.5964, 'remaining_time': 0.0}\n",
      " 83%|████████▎ | 10/12 [04:55<00:58, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2364, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.023516058921814, 'flops': 1608915507391.9507, 'remaining_time': 0.0}\n",
      "{'train_runtime': 3.0576, 'train_samples_per_second': 2.943, 'train_steps_per_second': 0.981, 'train_loss': 1.5656781792640686, 'epoch': 0.01, 'iter_time': 1.025452971458435, 'flops': 1605876529785.5964, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f2472965ea4216ae01d6741b3a6aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:13:30,892 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 4.942234039306641, 'eval_runtime': 7.5832, 'eval_samples_per_second': 13.187, 'eval_steps_per_second': 13.187, 'epoch': 0.01, 'iter_time': 4.820823550224304, 'flops': 341591191236.89557, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_10_1_adafactor_1_3_3\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [05:21<00:29, 29.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned slightly model's answer: \n",
      "Hi.Hello. For further information consult a urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.0008338968384145734\n",
      "Deleted model folder: ai_medical_0_10_1_adafactor_1_3_3\n",
      "Using hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "num_train_epochs: 20\n",
      "per_device_train_batch_size: 1\n",
      "optim: adafactor\n",
      "num_iterations: 1\n",
      "max_steps: 3\n",
      "gradient_accumulation_steps: 3\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 1646.750859264 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd69d8a9b74544489db75aba77e7e12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:13:50,258 - DEBUG - utilities - Step (1) Logs: {'loss': 2.2212, 'learning_rate': 0.0001, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      " 92%|█████████▏| 11/12 [05:22<00:29, 29.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2212, 'learning_rate': 0.0001, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:13:51,399 - DEBUG - utilities - Step (2) Logs: {'loss': 0.4669, 'learning_rate': 5e-05, 'epoch': 0.01, 'iter_time': 1.1403756141662598, 'flops': 1444042505651.0493, 'remaining_time': 1.1403756141662598}\n",
      " 92%|█████████▏| 11/12 [05:23<00:29, 29.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4669, 'learning_rate': 5e-05, 'epoch': 0.01, 'iter_time': 1.1403756141662598, 'flops': 1444042505651.0493, 'remaining_time': 1.1403756141662598}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:13:52,372 - DEBUG - utilities - Step (3) Logs: {'loss': 1.3921, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.057012915611267, 'flops': 1557928796273.6855, 'remaining_time': 0.0}\n",
      " 92%|█████████▏| 11/12 [05:24<00:29, 29.09s/it]2024-04-10 00:13:52,377 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 3.1048, 'train_samples_per_second': 2.899, 'train_steps_per_second': 0.966, 'total_flos': 138837393408.0, 'train_loss': 1.360078861316045, 'epoch': 0.01, 'iter_time': 1.0595853328704834, 'flops': 1554146521453.6787, 'remaining_time': 0.0}\n",
      " 92%|█████████▏| 11/12 [05:24<00:29, 29.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3921, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.057012915611267, 'flops': 1557928796273.6855, 'remaining_time': 0.0}\n",
      "{'train_runtime': 3.1048, 'train_samples_per_second': 2.899, 'train_steps_per_second': 0.966, 'train_loss': 1.360078861316045, 'epoch': 0.01, 'iter_time': 1.0595853328704834, 'flops': 1554146521453.6787, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db58f1550f94bd7afde9c6f571874d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 00:13:59,853 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 5.07048225402832, 'eval_runtime': 7.4669, 'eval_samples_per_second': 13.392, 'eval_steps_per_second': 13.392, 'epoch': 0.01, 'iter_time': 4.797343850135803, 'flops': 343263045282.31464, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ai_medical_0_20_1_adafactor_1_3_3\n",
      "Question input (test): Will Kalarchikai cure multiple ovarian cysts in PCOD?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [05:50<00:00, 29.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned slightly model's answer: \n",
      "Hi. I hope this helps. I hope. For more information consult a urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urologist online --> urolog\n",
      "Target answer output (test): Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Cosine Similarity: 0.00167919353905566\n",
      "Deleted model folder: ai_medical_0_20_1_adafactor_1_3_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function to find the best hyperparameters\n",
    "best_hyperparameters, best_loss ,df = find_best_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 1e-05, 'num_train_epochs': 20, 'per_device_train_batch_size': 1, 'optim': 'adafactor', 'num_iterations': 1, 'max_steps': 3, 'gradient_accumulation_steps': 3}\n",
      "Best loss: 3.747753620147705\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best loss:\", best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'eval_loss' inside the 'Evaluation Results' column\n",
    "df_sorted = df.sort_values(by='Evaluation Results', \n",
    "                           key=lambda x: x.apply(lambda d: d['eval_loss']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Evaluation Results</th>\n",
       "      <th>Training Output</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'learning_rate': 1e-05, 'num_train_epochs': 2...</td>\n",
       "      <td>{'eval_loss': 3.747753620147705, 'eval_runtime...</td>\n",
       "      <td>(3, 2.542485992113749, {'train_runtime': 3.056...</td>\n",
       "      <td>0.202080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'learning_rate': 1e-05, 'num_train_epochs': 1...</td>\n",
       "      <td>{'eval_loss': 3.842315673828125, 'eval_runtime...</td>\n",
       "      <td>(3, 2.943731149037679, {'train_runtime': 3.178...</td>\n",
       "      <td>0.202080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'learning_rate': 0.0001, 'num_train_epochs': ...</td>\n",
       "      <td>{'eval_loss': 3.955519914627075, 'eval_runtime...</td>\n",
       "      <td>(3, 2.735529979070028, {'train_runtime': 3.097...</td>\n",
       "      <td>0.000816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 1e-05, 'num_train_epochs': 5...</td>\n",
       "      <td>{'eval_loss': 3.987677574157715, 'eval_runtime...</td>\n",
       "      <td>(3, 3.4048125743865967, {'train_runtime': 3.02...</td>\n",
       "      <td>0.272767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 1e-05, 'num_train_epochs': 1...</td>\n",
       "      <td>{'eval_loss': 4.159300804138184, 'eval_runtime...</td>\n",
       "      <td>(3, 3.904948075612386, {'train_runtime': 3.377...</td>\n",
       "      <td>0.142329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Hyperparameters  \\\n",
       "7  {'learning_rate': 1e-05, 'num_train_epochs': 2...   \n",
       "6  {'learning_rate': 1e-05, 'num_train_epochs': 1...   \n",
       "8  {'learning_rate': 0.0001, 'num_train_epochs': ...   \n",
       "5  {'learning_rate': 1e-05, 'num_train_epochs': 5...   \n",
       "4  {'learning_rate': 1e-05, 'num_train_epochs': 1...   \n",
       "\n",
       "                                  Evaluation Results  \\\n",
       "7  {'eval_loss': 3.747753620147705, 'eval_runtime...   \n",
       "6  {'eval_loss': 3.842315673828125, 'eval_runtime...   \n",
       "8  {'eval_loss': 3.955519914627075, 'eval_runtime...   \n",
       "5  {'eval_loss': 3.987677574157715, 'eval_runtime...   \n",
       "4  {'eval_loss': 4.159300804138184, 'eval_runtime...   \n",
       "\n",
       "                                     Training Output  Cosine Similarity  \n",
       "7  (3, 2.542485992113749, {'train_runtime': 3.056...           0.202080  \n",
       "6  (3, 2.943731149037679, {'train_runtime': 3.178...           0.202080  \n",
       "8  (3, 2.735529979070028, {'train_runtime': 3.097...           0.000816  \n",
       "5  (3, 3.4048125743865967, {'train_runtime': 3.02...           0.272767  \n",
       "4  (3, 3.904948075612386, {'train_runtime': 3.377...           0.142329  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'Cosine Similarity' from largest to smallest\n",
    "df_cos = df.sort_values(by='Cosine Similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Evaluation Results</th>\n",
       "      <th>Training Output</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 1e-05, 'num_train_epochs': 5...</td>\n",
       "      <td>{'eval_loss': 3.987677574157715, 'eval_runtime...</td>\n",
       "      <td>(3, 3.4048125743865967, {'train_runtime': 3.02...</td>\n",
       "      <td>0.272767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 1e-06, 'num_train_epochs': 2...</td>\n",
       "      <td>{'eval_loss': 4.3534440994262695, 'eval_runtim...</td>\n",
       "      <td>(3, 3.999807039896647, {'train_runtime': 2.944...</td>\n",
       "      <td>0.225828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 1e-06, 'num_train_epochs': 1...</td>\n",
       "      <td>{'eval_loss': 4.424636363983154, 'eval_runtime...</td>\n",
       "      <td>(3, 4.1867062250773115, {'train_runtime': 3.24...</td>\n",
       "      <td>0.224779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 1e-06, 'num_train_epochs': 5...</td>\n",
       "      <td>{'eval_loss': 4.399848461151123, 'eval_runtime...</td>\n",
       "      <td>(3, 4.1223320960998535, {'train_runtime': 2.91...</td>\n",
       "      <td>0.224779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 1e-06, 'num_train_epochs': 1...</td>\n",
       "      <td>{'eval_loss': 4.3765645027160645, 'eval_runtim...</td>\n",
       "      <td>(3, 4.059745152791341, {'train_runtime': 2.928...</td>\n",
       "      <td>0.224779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'learning_rate': 1e-05, 'num_train_epochs': 1...</td>\n",
       "      <td>{'eval_loss': 3.842315673828125, 'eval_runtime...</td>\n",
       "      <td>(3, 2.943731149037679, {'train_runtime': 3.178...</td>\n",
       "      <td>0.202080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'learning_rate': 1e-05, 'num_train_epochs': 2...</td>\n",
       "      <td>{'eval_loss': 3.747753620147705, 'eval_runtime...</td>\n",
       "      <td>(3, 2.542485992113749, {'train_runtime': 3.056...</td>\n",
       "      <td>0.202080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 1e-05, 'num_train_epochs': 1...</td>\n",
       "      <td>{'eval_loss': 4.159300804138184, 'eval_runtime...</td>\n",
       "      <td>(3, 3.904948075612386, {'train_runtime': 3.377...</td>\n",
       "      <td>0.142329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'learning_rate': 0.0001, 'num_train_epochs': ...</td>\n",
       "      <td>{'eval_loss': 4.3177995681762695, 'eval_runtim...</td>\n",
       "      <td>(3, 1.7846872011820476, {'train_runtime': 3.14...</td>\n",
       "      <td>0.003605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'learning_rate': 0.0001, 'num_train_epochs': ...</td>\n",
       "      <td>{'eval_loss': 5.07048225402832, 'eval_runtime'...</td>\n",
       "      <td>(3, 1.360078861316045, {'train_runtime': 3.104...</td>\n",
       "      <td>0.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'learning_rate': 0.0001, 'num_train_epochs': ...</td>\n",
       "      <td>{'eval_loss': 4.942234039306641, 'eval_runtime...</td>\n",
       "      <td>(3, 1.5656781792640686, {'train_runtime': 3.05...</td>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'learning_rate': 0.0001, 'num_train_epochs': ...</td>\n",
       "      <td>{'eval_loss': 3.955519914627075, 'eval_runtime...</td>\n",
       "      <td>(3, 2.735529979070028, {'train_runtime': 3.097...</td>\n",
       "      <td>0.000816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Hyperparameters  \\\n",
       "5   {'learning_rate': 1e-05, 'num_train_epochs': 5...   \n",
       "3   {'learning_rate': 1e-06, 'num_train_epochs': 2...   \n",
       "0   {'learning_rate': 1e-06, 'num_train_epochs': 1...   \n",
       "1   {'learning_rate': 1e-06, 'num_train_epochs': 5...   \n",
       "2   {'learning_rate': 1e-06, 'num_train_epochs': 1...   \n",
       "6   {'learning_rate': 1e-05, 'num_train_epochs': 1...   \n",
       "7   {'learning_rate': 1e-05, 'num_train_epochs': 2...   \n",
       "4   {'learning_rate': 1e-05, 'num_train_epochs': 1...   \n",
       "9   {'learning_rate': 0.0001, 'num_train_epochs': ...   \n",
       "11  {'learning_rate': 0.0001, 'num_train_epochs': ...   \n",
       "10  {'learning_rate': 0.0001, 'num_train_epochs': ...   \n",
       "8   {'learning_rate': 0.0001, 'num_train_epochs': ...   \n",
       "\n",
       "                                   Evaluation Results  \\\n",
       "5   {'eval_loss': 3.987677574157715, 'eval_runtime...   \n",
       "3   {'eval_loss': 4.3534440994262695, 'eval_runtim...   \n",
       "0   {'eval_loss': 4.424636363983154, 'eval_runtime...   \n",
       "1   {'eval_loss': 4.399848461151123, 'eval_runtime...   \n",
       "2   {'eval_loss': 4.3765645027160645, 'eval_runtim...   \n",
       "6   {'eval_loss': 3.842315673828125, 'eval_runtime...   \n",
       "7   {'eval_loss': 3.747753620147705, 'eval_runtime...   \n",
       "4   {'eval_loss': 4.159300804138184, 'eval_runtime...   \n",
       "9   {'eval_loss': 4.3177995681762695, 'eval_runtim...   \n",
       "11  {'eval_loss': 5.07048225402832, 'eval_runtime'...   \n",
       "10  {'eval_loss': 4.942234039306641, 'eval_runtime...   \n",
       "8   {'eval_loss': 3.955519914627075, 'eval_runtime...   \n",
       "\n",
       "                                      Training Output  Cosine Similarity  \n",
       "5   (3, 3.4048125743865967, {'train_runtime': 3.02...           0.272767  \n",
       "3   (3, 3.999807039896647, {'train_runtime': 2.944...           0.225828  \n",
       "0   (3, 4.1867062250773115, {'train_runtime': 3.24...           0.224779  \n",
       "1   (3, 4.1223320960998535, {'train_runtime': 2.91...           0.224779  \n",
       "2   (3, 4.059745152791341, {'train_runtime': 2.928...           0.224779  \n",
       "6   (3, 2.943731149037679, {'train_runtime': 3.178...           0.202080  \n",
       "7   (3, 2.542485992113749, {'train_runtime': 3.056...           0.202080  \n",
       "4   (3, 3.904948075612386, {'train_runtime': 3.377...           0.142329  \n",
       "9   (3, 1.7846872011820476, {'train_runtime': 3.14...           0.003605  \n",
       "11  (3, 1.360078861316045, {'train_runtime': 3.104...           0.001679  \n",
       "10  (3, 1.5656781792640686, {'train_runtime': 3.05...           0.000834  \n",
       "8   (3, 2.735529979070028, {'train_runtime': 3.097...           0.000816  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
