{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 13:37:12,147 - DEBUG - utilities - Config: datasets.path: c:\\Blog\\How-to-Finetuning-Large-Language-Models\\content\\ai-medical-chatbot_processed.jsonl\n",
      "datasets.use_hf: false\n",
      "model.max_length: 2048\n",
      "model.pretrained_name: EleutherAI/pythia-70m\n",
      "verbose: true\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize False c:\\Blog\\How-to-Finetuning-Large-Language-Models\\content\\ai-medical-chatbot_processed.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 13:37:12,483 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-59ea57fe03c7d0e8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/dataset_info.json\n",
      "2024-04-08 13:37:12,598 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-59ea57fe03c7d0e8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1350\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 150\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 13:37:13,810 - DEBUG - __main__ - Select CPU device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): ### Question:\n",
      "Will Kalarchikai cure multiple ovarian cysts in PCOD?\n",
      "### Answer:\n",
      "Correct answer from ai-medical-chatbot: Hello. I just read your query. See Kalarachi Kai choornam is helpful in amenorrhea. As far as small cysts are concerned they are unmatured eggs which failed to induce menstrual cycle previously, as a result, they got collected in the ovary and they will remain in the ovary. Now, you have got your periods you can start trying for conception. But I advise you to do it under the supervision of a nearby gynecologist because egg size is important while conception and that you can know by ovulation study. Ovulation study is performed under the supervision of a gynecologist. For gall stones, surgical intervention is required generally. Medicine is not of much help.\n",
      "Model's answer: \n",
      "\n",
      "\n",
      "The answer is \"Yes\" and \"No\"\n",
      "\n",
      "The answer is \"Yes\" and \"No\"\n",
      "\n",
      "The answer is \"Yes\" and \"No\"\n",
      "\n",
      "The answer is \"Yes\" and \"No\"\n",
      "\n",
      "The answer is \"Yes\" and \"No\"\n",
      "\n",
      "The answer is \"Yes\" and \"No\"\n",
      "\n",
      "The answer is \"Yes\n",
      "GPTNeoXForCausalLM(\n",
      "  (gpt_neox): GPTNeoXModel(\n",
      "    (embed_in): Embedding(50304, 512)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x GPTNeoXLayer(\n",
      "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (attention): GPTNeoXAttention(\n",
      "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): GPTNeoXMLP(\n",
      "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (act): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
      ")\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 2195.667812352 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67580c71841b4f1aa699c6a3d89e3230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 13:37:16,914 - DEBUG - utilities - Step (1) Logs: {'loss': 4.8075, 'learning_rate': 1e-05, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8075, 'learning_rate': 1e-05, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 13:37:18,667 - DEBUG - utilities - Step (2) Logs: {'loss': 4.059, 'learning_rate': 5e-06, 'epoch': 0.01, 'iter_time': 1.7527174949645996, 'flops': 1252722026601.5242, 'remaining_time': 1.7527174949645996}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.059, 'learning_rate': 5e-06, 'epoch': 0.01, 'iter_time': 1.7527174949645996, 'flops': 1252722026601.5242, 'remaining_time': 1.7527174949645996}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 13:37:19,832 - DEBUG - utilities - Step (3) Logs: {'loss': 4.6117, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.4589784145355225, 'flops': 1504935090524.2888, 'remaining_time': 0.0}\n",
      "2024-04-08 13:37:19,832 - DEBUG - utilities - Step (3) Logs: {'train_runtime': 4.5758, 'train_samples_per_second': 2.623, 'train_steps_per_second': 0.656, 'total_flos': 405255094272.0, 'train_loss': 4.492728392283122, 'epoch': 0.01, 'iter_time': 1.45903742313385, 'flops': 1504874225663.0742, 'remaining_time': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6117, 'learning_rate': 0.0, 'epoch': 0.01, 'iter_time': 1.4589784145355225, 'flops': 1504935090524.2888, 'remaining_time': 0.0}\n",
      "{'train_runtime': 4.5758, 'train_samples_per_second': 2.623, 'train_steps_per_second': 0.656, 'train_loss': 4.492728392283122, 'epoch': 0.01, 'iter_time': 1.45903742313385, 'flops': 1504874225663.0742, 'remaining_time': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import tempfile\n",
    "import logging\n",
    "import random\n",
    "import config\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "from utilities import *\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForCausalLM\n",
    "from llama import BasicModelRunner\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "global_config = None\n",
    "\n",
    "### Load the Lamini docs dataset\n",
    "\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "# Join the folder path\n",
    "folder_path = os.path.join(current_directory, \"content\")\n",
    "dataset_name = \"ai-medical-chatbot_processed.jsonl\"\n",
    "dataset_path = os.path.join(folder_path, dataset_name)\n",
    "#dataset_path = f\"/content/{dataset_name}\"\n",
    "use_hf = False\n",
    "\n",
    "### Set up the model, training config, and tokenizer\n",
    "\n",
    "model_name = \"EleutherAI/pythia-70m\"\n",
    "\n",
    "training_config = {\n",
    "    \"model\": {\n",
    "        \"pretrained_name\": model_name,\n",
    "        \"max_length\" : 2048\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"use_hf\": use_hf,\n",
    "        \"path\": dataset_path\n",
    "    },\n",
    "    \"verbose\": True\n",
    "}\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_dataset, test_dataset = tokenize_and_split_data(training_config, tokenizer)\n",
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "\n",
    "### Load the base model\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "device_count = torch.cuda.device_count()\n",
    "if device_count > 0:\n",
    "    logger.debug(\"Select GPU device\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    logger.debug(\"Select CPU device\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "base_model.to(device)\n",
    "\n",
    "### Define function to carry out inference\n",
    "def inference_new(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
    "  # Tokenize\n",
    "  input_ids = tokenizer.encode(\n",
    "      text,\n",
    "      return_tensors=\"pt\",\n",
    "      truncation=True,\n",
    "      max_length=max_input_tokens\n",
    "  )\n",
    "\n",
    "  # Generate\n",
    "  device = model.device\n",
    "  attention_mask = torch.ones_like(input_ids)  # Create mask with all 1s\n",
    "\n",
    "  # Fix: Mask all padding tokens, including the first element\n",
    "  attention_mask[input_ids == tokenizer.pad_token_id] = 0\n",
    "\n",
    "  generated_tokens_with_prompt = model.generate(\n",
    "      input_ids.to(device),\n",
    "      max_length=max_output_tokens,\n",
    "      attention_mask=attention_mask,\n",
    "      pad_token_id=tokenizer.eos_token_id  # Set pad token\n",
    "  )\n",
    "\n",
    "  # Decode\n",
    "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "  # Strip the prompt\n",
    "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "  return generated_text_answer\n",
    "\n",
    "test_text = test_dataset[0]['question']\n",
    "print(\"Question input (test):\", test_text)\n",
    "print(f\"Correct answer from ai-medical-chatbot: {test_dataset[0]['answer']}\")\n",
    "print(\"Model's answer: \")\n",
    "print(inference_new(test_text, base_model, tokenizer))\n",
    "### Setup training\n",
    "max_steps = 3\n",
    "trained_model_name = f\"ai_medical_{max_steps}_steps\"\n",
    "output_dir = trained_model_name\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\n",
    "  # Learning rate\n",
    "  learning_rate=1.0e-5,\n",
    "  # Number of training epochs\n",
    "  num_train_epochs=10,\n",
    "  # Max steps to train for (each step is a batch of data)\n",
    "  # Overrides num_train_epochs, if not -1\n",
    "  max_steps=max_steps,\n",
    "  # Batch size for training\n",
    "  per_device_train_batch_size=1,\n",
    "  # Directory to save model checkpoints\n",
    "  output_dir=output_dir,\n",
    "  # Other arguments\n",
    "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
    "  disable_tqdm=False, # Disable progress bars\n",
    "  eval_steps=120, # Number of update steps between two evaluations\n",
    "  save_steps=120, # After # steps model is saved\n",
    "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
    "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "  evaluation_strategy=\"steps\",\n",
    "  logging_strategy=\"steps\",\n",
    "  logging_steps=1,\n",
    "  optim=\"adafactor\",\n",
    "  gradient_accumulation_steps = 4,\n",
    "  gradient_checkpointing=False,\n",
    "  # Parameters for early stopping\n",
    "  load_best_model_at_end=True,\n",
    "  save_total_limit=1,\n",
    "  metric_for_best_model=\"eval_loss\",\n",
    "  greater_is_better=False\n",
    ")\n",
    "\n",
    "model_flops = (\n",
    "  base_model.floating_point_ops(\n",
    "    {\n",
    "       \"input_ids\": torch.zeros(\n",
    "           (1, training_config[\"model\"][\"max_length\"])\n",
    "      )\n",
    "    }\n",
    "  )\n",
    "  * training_args.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "print(base_model)\n",
    "print(\"Memory footprint\", base_model.get_memory_footprint() / 1e9, \"GB\")\n",
    "print(\"Flops\", model_flops / 1e9, \"GFLOPs\")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    model_flops=model_flops,\n",
    "    total_steps=max_steps,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "training_output = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e320ab1ca6413a8fb2545cd6da4f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 13:38:04,209 - DEBUG - utilities - Step (3) Logs: {'eval_loss': 4.126183986663818, 'eval_runtime': 10.9009, 'eval_samples_per_second': 13.76, 'eval_steps_per_second': 13.76, 'epoch': 0.01, 'iter_time': 23.647719264030457, 'flops': 92849030717.8053, 'remaining_time': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.126183986663818,\n",
       " 'eval_runtime': 10.9009,\n",
       " 'eval_samples_per_second': 13.76,\n",
       " 'eval_steps_per_second': 13.76,\n",
       " 'epoch': 0.01,\n",
       " 'iter_time': 23.647719264030457,\n",
       " 'flops': 92849030717.8053,\n",
       " 'remaining_time': 0.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 14:13:51,361 - DEBUG - utilities - Config: datasets.path: c:\\Blog\\How-to-Finetuning-Large-Language-Models\\content\\ai-medical-chatbot_processed.jsonl\n",
      "datasets.use_hf: false\n",
      "model.max_length: 2048\n",
      "model.pretrained_name: EleutherAI/pythia-70m\n",
      "verbose: true\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize False c:\\Blog\\How-to-Finetuning-Large-Language-Models\\content\\ai-medical-chatbot_processed.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 14:13:51,698 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-59ea57fe03c7d0e8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/dataset_info.json\n",
      "2024-04-08 14:13:51,700 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-59ea57fe03c7d0e8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/dataset_info.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07de0eb90cb4d83befe948fc70e88fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/337 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3498, 'learning_rate': 0.0001, 'epoch': 0.0}\n",
      "{'loss': 3.5943, 'learning_rate': 9.970238095238096e-05, 'epoch': 0.01}\n",
      "{'loss': 4.0899, 'learning_rate': 9.940476190476191e-05, 'epoch': 0.01}\n",
      "{'loss': 4.3327, 'learning_rate': 9.910714285714286e-05, 'epoch': 0.01}\n",
      "{'loss': 4.5691, 'learning_rate': 9.880952380952381e-05, 'epoch': 0.01}\n",
      "{'loss': 4.2784, 'learning_rate': 9.851190476190477e-05, 'epoch': 0.02}\n",
      "{'loss': 2.7409, 'learning_rate': 9.821428571428572e-05, 'epoch': 0.02}\n",
      "{'loss': 3.8119, 'learning_rate': 9.791666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.2355, 'learning_rate': 9.761904761904762e-05, 'epoch': 0.03}\n",
      "{'loss': 3.6393, 'learning_rate': 9.732142857142858e-05, 'epoch': 0.03}\n",
      "{'loss': 4.0414, 'learning_rate': 9.702380952380953e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2732, 'learning_rate': 9.672619047619048e-05, 'epoch': 0.04}\n",
      "{'loss': 3.7015, 'learning_rate': 9.642857142857143e-05, 'epoch': 0.04}\n",
      "{'loss': 3.1064, 'learning_rate': 9.613095238095238e-05, 'epoch': 0.04}\n",
      "{'loss': 4.3034, 'learning_rate': 9.583333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.5326, 'learning_rate': 9.553571428571429e-05, 'epoch': 0.05}\n",
      "{'loss': 3.1048, 'learning_rate': 9.523809523809524e-05, 'epoch': 0.05}\n",
      "{'loss': 3.6595, 'learning_rate': 9.494047619047619e-05, 'epoch': 0.05}\n",
      "{'loss': 3.8368, 'learning_rate': 9.464285714285715e-05, 'epoch': 0.06}\n",
      "{'loss': 3.1315, 'learning_rate': 9.43452380952381e-05, 'epoch': 0.06}\n",
      "{'loss': 2.7583, 'learning_rate': 9.404761904761905e-05, 'epoch': 0.06}\n",
      "{'loss': 4.0749, 'learning_rate': 9.375e-05, 'epoch': 0.07}\n",
      "{'loss': 3.9584, 'learning_rate': 9.345238095238095e-05, 'epoch': 0.07}\n",
      "{'loss': 1.582, 'learning_rate': 9.31547619047619e-05, 'epoch': 0.07}\n",
      "{'loss': 2.4571, 'learning_rate': 9.285714285714286e-05, 'epoch': 0.07}\n",
      "{'loss': 3.7215, 'learning_rate': 9.255952380952382e-05, 'epoch': 0.08}\n",
      "{'loss': 3.6245, 'learning_rate': 9.226190476190478e-05, 'epoch': 0.08}\n",
      "{'loss': 1.944, 'learning_rate': 9.196428571428572e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0884, 'learning_rate': 9.166666666666667e-05, 'epoch': 0.09}\n",
      "{'loss': 4.2388, 'learning_rate': 9.136904761904762e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4463, 'learning_rate': 9.107142857142857e-05, 'epoch': 0.09}\n",
      "{'loss': 1.6019, 'learning_rate': 9.077380952380952e-05, 'epoch': 0.09}\n",
      "{'loss': 4.3164, 'learning_rate': 9.047619047619048e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9906, 'learning_rate': 9.017857142857143e-05, 'epoch': 0.1}\n",
      "{'loss': 3.9556, 'learning_rate': 8.988095238095238e-05, 'epoch': 0.1}\n",
      "{'loss': 4.1588, 'learning_rate': 8.958333333333335e-05, 'epoch': 0.11}\n",
      "{'loss': 2.2123, 'learning_rate': 8.92857142857143e-05, 'epoch': 0.11}\n",
      "{'loss': 2.3233, 'learning_rate': 8.898809523809524e-05, 'epoch': 0.11}\n",
      "{'loss': 3.1203, 'learning_rate': 8.869047619047619e-05, 'epoch': 0.12}\n",
      "{'loss': 2.8233, 'learning_rate': 8.839285714285714e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7323, 'learning_rate': 8.80952380952381e-05, 'epoch': 0.12}\n",
      "{'loss': 2.3014, 'learning_rate': 8.779761904761905e-05, 'epoch': 0.12}\n",
      "{'loss': 4.4326, 'learning_rate': 8.75e-05, 'epoch': 0.13}\n",
      "{'loss': 2.1098, 'learning_rate': 8.720238095238095e-05, 'epoch': 0.13}\n",
      "{'loss': 2.9339, 'learning_rate': 8.690476190476192e-05, 'epoch': 0.13}\n",
      "{'loss': 3.8424, 'learning_rate': 8.660714285714287e-05, 'epoch': 0.14}\n",
      "{'loss': 3.4515, 'learning_rate': 8.630952380952382e-05, 'epoch': 0.14}\n",
      "{'loss': 4.7984, 'learning_rate': 8.601190476190477e-05, 'epoch': 0.14}\n",
      "{'loss': 3.1905, 'learning_rate': 8.571428571428571e-05, 'epoch': 0.15}\n",
      "{'loss': 1.2572, 'learning_rate': 8.541666666666666e-05, 'epoch': 0.15}\n",
      "{'loss': 3.2451, 'learning_rate': 8.511904761904762e-05, 'epoch': 0.15}\n",
      "{'loss': 3.7652, 'learning_rate': 8.482142857142857e-05, 'epoch': 0.15}\n",
      "{'loss': 3.7476, 'learning_rate': 8.452380952380952e-05, 'epoch': 0.16}\n",
      "{'loss': 3.5734, 'learning_rate': 8.422619047619049e-05, 'epoch': 0.16}\n",
      "{'loss': 3.189, 'learning_rate': 8.392857142857144e-05, 'epoch': 0.16}\n",
      "{'loss': 3.0106, 'learning_rate': 8.363095238095239e-05, 'epoch': 0.17}\n",
      "{'loss': 3.0585, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.17}\n",
      "{'loss': 4.137, 'learning_rate': 8.30357142857143e-05, 'epoch': 0.17}\n",
      "{'loss': 2.6588, 'learning_rate': 8.273809523809524e-05, 'epoch': 0.17}\n",
      "{'loss': 3.1205, 'learning_rate': 8.244047619047619e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1531, 'learning_rate': 8.214285714285714e-05, 'epoch': 0.18}\n",
      "{'loss': 4.4293, 'learning_rate': 8.184523809523809e-05, 'epoch': 0.18}\n",
      "{'loss': 2.6131, 'learning_rate': 8.154761904761904e-05, 'epoch': 0.19}\n",
      "{'loss': 1.3322, 'learning_rate': 8.125000000000001e-05, 'epoch': 0.19}\n",
      "{'loss': 4.1776, 'learning_rate': 8.095238095238096e-05, 'epoch': 0.19}\n",
      "{'loss': 3.5125, 'learning_rate': 8.065476190476191e-05, 'epoch': 0.2}\n",
      "{'loss': 3.0466, 'learning_rate': 8.035714285714287e-05, 'epoch': 0.2}\n",
      "{'loss': 4.3579, 'learning_rate': 8.005952380952382e-05, 'epoch': 0.2}\n",
      "{'loss': 4.4033, 'learning_rate': 7.976190476190477e-05, 'epoch': 0.2}\n",
      "{'loss': 2.6611, 'learning_rate': 7.946428571428571e-05, 'epoch': 0.21}\n",
      "{'loss': 2.6361, 'learning_rate': 7.916666666666666e-05, 'epoch': 0.21}\n",
      "{'loss': 3.8763, 'learning_rate': 7.886904761904761e-05, 'epoch': 0.21}\n",
      "{'loss': 1.863, 'learning_rate': 7.857142857142858e-05, 'epoch': 0.22}\n",
      "{'loss': 2.7074, 'learning_rate': 7.827380952380953e-05, 'epoch': 0.22}\n",
      "{'loss': 3.7864, 'learning_rate': 7.797619047619048e-05, 'epoch': 0.22}\n",
      "{'loss': 4.3647, 'learning_rate': 7.767857142857144e-05, 'epoch': 0.23}\n",
      "{'loss': 2.0268, 'learning_rate': 7.738095238095239e-05, 'epoch': 0.23}\n",
      "{'loss': 3.9439, 'learning_rate': 7.708333333333334e-05, 'epoch': 0.23}\n",
      "{'loss': 3.1056, 'learning_rate': 7.67857142857143e-05, 'epoch': 0.23}\n",
      "{'loss': 3.6421, 'learning_rate': 7.648809523809523e-05, 'epoch': 0.24}\n",
      "{'loss': 2.236, 'learning_rate': 7.619047619047618e-05, 'epoch': 0.24}\n",
      "{'loss': 2.048, 'learning_rate': 7.589285714285714e-05, 'epoch': 0.24}\n",
      "{'loss': 3.2044, 'learning_rate': 7.55952380952381e-05, 'epoch': 0.25}\n",
      "{'loss': 1.5714, 'learning_rate': 7.529761904761905e-05, 'epoch': 0.25}\n",
      "{'loss': 1.3013, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.25}\n",
      "{'loss': 2.0288, 'learning_rate': 7.470238095238096e-05, 'epoch': 0.25}\n",
      "{'loss': 3.0881, 'learning_rate': 7.440476190476191e-05, 'epoch': 0.26}\n",
      "{'loss': 1.2421, 'learning_rate': 7.410714285714286e-05, 'epoch': 0.26}\n",
      "{'loss': 3.2601, 'learning_rate': 7.380952380952382e-05, 'epoch': 0.26}\n",
      "{'loss': 4.4198, 'learning_rate': 7.351190476190477e-05, 'epoch': 0.27}\n",
      "{'loss': 3.0102, 'learning_rate': 7.321428571428571e-05, 'epoch': 0.27}\n",
      "{'loss': 4.0276, 'learning_rate': 7.291666666666667e-05, 'epoch': 0.27}\n",
      "{'loss': 4.1681, 'learning_rate': 7.261904761904762e-05, 'epoch': 0.28}\n",
      "{'loss': 2.3566, 'learning_rate': 7.232142857142858e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9857, 'learning_rate': 7.202380952380953e-05, 'epoch': 0.28}\n",
      "{'loss': 3.2029, 'learning_rate': 7.172619047619048e-05, 'epoch': 0.28}\n",
      "{'loss': 2.7548, 'learning_rate': 7.142857142857143e-05, 'epoch': 0.29}\n",
      "{'loss': 3.4972, 'learning_rate': 7.113095238095239e-05, 'epoch': 0.29}\n",
      "{'loss': 2.6026, 'learning_rate': 7.083333333333334e-05, 'epoch': 0.29}\n",
      "{'loss': 1.1729, 'learning_rate': 7.053571428571429e-05, 'epoch': 0.3}\n",
      "{'loss': 2.4764, 'learning_rate': 7.023809523809524e-05, 'epoch': 0.3}\n",
      "{'loss': 2.2267, 'learning_rate': 6.99404761904762e-05, 'epoch': 0.3}\n",
      "{'loss': 1.3315, 'learning_rate': 6.964285714285715e-05, 'epoch': 0.31}\n",
      "{'loss': 3.4792, 'learning_rate': 6.93452380952381e-05, 'epoch': 0.31}\n",
      "{'loss': 3.1287, 'learning_rate': 6.904761904761905e-05, 'epoch': 0.31}\n",
      "{'loss': 3.2335, 'learning_rate': 6.875e-05, 'epoch': 0.31}\n",
      "{'loss': 1.7889, 'learning_rate': 6.845238095238096e-05, 'epoch': 0.32}\n",
      "{'loss': 2.9515, 'learning_rate': 6.815476190476191e-05, 'epoch': 0.32}\n",
      "{'loss': 2.3809, 'learning_rate': 6.785714285714286e-05, 'epoch': 0.32}\n",
      "{'loss': 3.2164, 'learning_rate': 6.755952380952381e-05, 'epoch': 0.33}\n",
      "{'loss': 2.9388, 'learning_rate': 6.726190476190477e-05, 'epoch': 0.33}\n",
      "{'loss': 3.4014, 'learning_rate': 6.696428571428572e-05, 'epoch': 0.33}\n",
      "{'loss': 3.0458, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.33}\n",
      "{'loss': 2.0687, 'learning_rate': 6.636904761904762e-05, 'epoch': 0.34}\n",
      "{'loss': 3.1212, 'learning_rate': 6.607142857142857e-05, 'epoch': 0.34}\n",
      "{'loss': 3.6198, 'learning_rate': 6.577380952380953e-05, 'epoch': 0.34}\n",
      "{'loss': 2.5348, 'learning_rate': 6.547619047619048e-05, 'epoch': 0.35}\n",
      "{'loss': 2.688, 'learning_rate': 6.517857142857143e-05, 'epoch': 0.35}\n",
      "{'loss': 2.4305, 'learning_rate': 6.488095238095238e-05, 'epoch': 0.35}\n",
      "{'loss': 2.3155, 'learning_rate': 6.458333333333334e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc803f1d0e6478c9562c38aeca0433e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5055737495422363, 'eval_runtime': 16.0339, 'eval_samples_per_second': 9.355, 'eval_steps_per_second': 9.355, 'epoch': 0.36}\n",
      "{'loss': 1.2407, 'learning_rate': 6.428571428571429e-05, 'epoch': 0.36}\n",
      "{'loss': 3.3098, 'learning_rate': 6.398809523809524e-05, 'epoch': 0.36}\n",
      "{'loss': 3.2247, 'learning_rate': 6.369047619047619e-05, 'epoch': 0.36}\n",
      "{'loss': 1.895, 'learning_rate': 6.339285714285714e-05, 'epoch': 0.37}\n",
      "{'loss': 3.9257, 'learning_rate': 6.30952380952381e-05, 'epoch': 0.37}\n",
      "{'loss': 1.2035, 'learning_rate': 6.279761904761905e-05, 'epoch': 0.37}\n",
      "{'loss': 2.052, 'learning_rate': 6.25e-05, 'epoch': 0.38}\n",
      "{'loss': 1.5096, 'learning_rate': 6.220238095238095e-05, 'epoch': 0.38}\n",
      "{'loss': 2.0295, 'learning_rate': 6.19047619047619e-05, 'epoch': 0.38}\n",
      "{'loss': 2.5698, 'learning_rate': 6.160714285714286e-05, 'epoch': 0.39}\n",
      "{'loss': 2.9957, 'learning_rate': 6.130952380952381e-05, 'epoch': 0.39}\n",
      "{'loss': 3.6596, 'learning_rate': 6.101190476190477e-05, 'epoch': 0.39}\n",
      "{'loss': 2.9265, 'learning_rate': 6.0714285714285715e-05, 'epoch': 0.39}\n",
      "{'loss': 3.0, 'learning_rate': 6.041666666666667e-05, 'epoch': 0.4}\n",
      "{'loss': 3.1097, 'learning_rate': 6.011904761904762e-05, 'epoch': 0.4}\n",
      "{'loss': 3.5207, 'learning_rate': 5.982142857142857e-05, 'epoch': 0.4}\n",
      "{'loss': 3.3001, 'learning_rate': 5.9523809523809524e-05, 'epoch': 0.41}\n",
      "{'loss': 1.1117, 'learning_rate': 5.922619047619048e-05, 'epoch': 0.41}\n",
      "{'loss': 2.9343, 'learning_rate': 5.8928571428571435e-05, 'epoch': 0.41}\n",
      "{'loss': 4.3266, 'learning_rate': 5.863095238095239e-05, 'epoch': 0.41}\n",
      "{'loss': 1.1671, 'learning_rate': 5.833333333333334e-05, 'epoch': 0.42}\n",
      "{'loss': 0.6583, 'learning_rate': 5.803571428571429e-05, 'epoch': 0.42}\n",
      "{'loss': 2.1087, 'learning_rate': 5.773809523809524e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9418, 'learning_rate': 5.744047619047619e-05, 'epoch': 0.43}\n",
      "{'loss': 2.3651, 'learning_rate': 5.714285714285714e-05, 'epoch': 0.43}\n",
      "{'loss': 3.277, 'learning_rate': 5.6845238095238094e-05, 'epoch': 0.43}\n",
      "{'loss': 1.5883, 'learning_rate': 5.6547619047619046e-05, 'epoch': 0.44}\n",
      "{'loss': 3.0356, 'learning_rate': 5.6250000000000005e-05, 'epoch': 0.44}\n",
      "{'loss': 4.47, 'learning_rate': 5.595238095238096e-05, 'epoch': 0.44}\n",
      "{'loss': 3.2145, 'learning_rate': 5.565476190476191e-05, 'epoch': 0.44}\n",
      "{'loss': 1.1771, 'learning_rate': 5.535714285714286e-05, 'epoch': 0.45}\n",
      "{'loss': 1.6849, 'learning_rate': 5.5059523809523814e-05, 'epoch': 0.45}\n",
      "{'loss': 2.2953, 'learning_rate': 5.4761904761904766e-05, 'epoch': 0.45}\n",
      "{'loss': 2.0922, 'learning_rate': 5.446428571428571e-05, 'epoch': 0.46}\n",
      "{'loss': 1.5632, 'learning_rate': 5.4166666666666664e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8964, 'learning_rate': 5.3869047619047616e-05, 'epoch': 0.46}\n",
      "{'loss': 2.7399, 'learning_rate': 5.3571428571428575e-05, 'epoch': 0.47}\n",
      "{'loss': 0.8842, 'learning_rate': 5.327380952380953e-05, 'epoch': 0.47}\n",
      "{'loss': 3.0809, 'learning_rate': 5.297619047619048e-05, 'epoch': 0.47}\n",
      "{'loss': 0.5438, 'learning_rate': 5.267857142857143e-05, 'epoch': 0.47}\n",
      "{'loss': 3.7718, 'learning_rate': 5.2380952380952384e-05, 'epoch': 0.48}\n",
      "{'loss': 3.0367, 'learning_rate': 5.208333333333334e-05, 'epoch': 0.48}\n",
      "{'loss': 4.4539, 'learning_rate': 5.1785714285714296e-05, 'epoch': 0.48}\n",
      "{'loss': 1.0047, 'learning_rate': 5.1488095238095234e-05, 'epoch': 0.49}\n",
      "{'loss': 0.9312, 'learning_rate': 5.119047619047619e-05, 'epoch': 0.49}\n",
      "{'loss': 1.047, 'learning_rate': 5.089285714285714e-05, 'epoch': 0.49}\n",
      "{'loss': 2.0087, 'learning_rate': 5.05952380952381e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7062, 'learning_rate': 5.029761904761905e-05, 'epoch': 0.5}\n",
      "{'loss': 2.5152, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
      "{'loss': 2.9641, 'learning_rate': 4.9702380952380955e-05, 'epoch': 0.5}\n",
      "{'loss': 1.5265, 'learning_rate': 4.940476190476191e-05, 'epoch': 0.51}\n",
      "{'loss': 3.268, 'learning_rate': 4.910714285714286e-05, 'epoch': 0.51}\n",
      "{'loss': 4.0579, 'learning_rate': 4.880952380952381e-05, 'epoch': 0.51}\n",
      "{'loss': 2.9185, 'learning_rate': 4.8511904761904764e-05, 'epoch': 0.52}\n",
      "{'loss': 2.1444, 'learning_rate': 4.8214285714285716e-05, 'epoch': 0.52}\n",
      "{'loss': 2.4246, 'learning_rate': 4.791666666666667e-05, 'epoch': 0.52}\n",
      "{'loss': 2.2972, 'learning_rate': 4.761904761904762e-05, 'epoch': 0.52}\n",
      "{'loss': 1.4844, 'learning_rate': 4.732142857142857e-05, 'epoch': 0.53}\n",
      "{'loss': 3.1052, 'learning_rate': 4.7023809523809525e-05, 'epoch': 0.53}\n",
      "{'loss': 2.4136, 'learning_rate': 4.672619047619048e-05, 'epoch': 0.53}\n",
      "{'loss': 1.1247, 'learning_rate': 4.642857142857143e-05, 'epoch': 0.54}\n",
      "{'loss': 2.4237, 'learning_rate': 4.613095238095239e-05, 'epoch': 0.54}\n",
      "{'loss': 2.8374, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.54}\n",
      "{'loss': 2.8918, 'learning_rate': 4.5535714285714286e-05, 'epoch': 0.55}\n",
      "{'loss': 0.6525, 'learning_rate': 4.523809523809524e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0619, 'learning_rate': 4.494047619047619e-05, 'epoch': 0.55}\n",
      "{'loss': 1.1347, 'learning_rate': 4.464285714285715e-05, 'epoch': 0.55}\n",
      "{'loss': 3.0337, 'learning_rate': 4.4345238095238095e-05, 'epoch': 0.56}\n",
      "{'loss': 2.972, 'learning_rate': 4.404761904761905e-05, 'epoch': 0.56}\n",
      "{'loss': 4.2725, 'learning_rate': 4.375e-05, 'epoch': 0.56}\n",
      "{'loss': 2.6569, 'learning_rate': 4.345238095238096e-05, 'epoch': 0.57}\n",
      "{'loss': 2.3571, 'learning_rate': 4.315476190476191e-05, 'epoch': 0.57}\n",
      "{'loss': 0.9643, 'learning_rate': 4.2857142857142856e-05, 'epoch': 0.57}\n",
      "{'loss': 1.9201, 'learning_rate': 4.255952380952381e-05, 'epoch': 0.57}\n",
      "{'loss': 1.0898, 'learning_rate': 4.226190476190476e-05, 'epoch': 0.58}\n",
      "{'loss': 2.3936, 'learning_rate': 4.196428571428572e-05, 'epoch': 0.58}\n",
      "{'loss': 3.8513, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.58}\n",
      "{'loss': 1.4736, 'learning_rate': 4.136904761904762e-05, 'epoch': 0.59}\n",
      "{'loss': 3.5633, 'learning_rate': 4.107142857142857e-05, 'epoch': 0.59}\n",
      "{'loss': 3.2191, 'learning_rate': 4.077380952380952e-05, 'epoch': 0.59}\n",
      "{'loss': 1.9654, 'learning_rate': 4.047619047619048e-05, 'epoch': 0.6}\n",
      "{'loss': 2.2754, 'learning_rate': 4.017857142857143e-05, 'epoch': 0.6}\n",
      "{'loss': 2.3386, 'learning_rate': 3.9880952380952386e-05, 'epoch': 0.6}\n",
      "{'loss': 4.1183, 'learning_rate': 3.958333333333333e-05, 'epoch': 0.6}\n",
      "{'loss': 3.2385, 'learning_rate': 3.928571428571429e-05, 'epoch': 0.61}\n",
      "{'loss': 2.065, 'learning_rate': 3.898809523809524e-05, 'epoch': 0.61}\n",
      "{'loss': 3.1148, 'learning_rate': 3.8690476190476195e-05, 'epoch': 0.61}\n",
      "{'loss': 2.9477, 'learning_rate': 3.839285714285715e-05, 'epoch': 0.62}\n",
      "{'loss': 2.9122, 'learning_rate': 3.809523809523809e-05, 'epoch': 0.62}\n",
      "{'loss': 2.8971, 'learning_rate': 3.779761904761905e-05, 'epoch': 0.62}\n",
      "{'loss': 2.8599, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.63}\n",
      "{'loss': 2.6716, 'learning_rate': 3.7202380952380956e-05, 'epoch': 0.63}\n",
      "{'loss': 2.2699, 'learning_rate': 3.690476190476191e-05, 'epoch': 0.63}\n",
      "{'loss': 2.6592, 'learning_rate': 3.6607142857142853e-05, 'epoch': 0.63}\n",
      "{'loss': 3.1965, 'learning_rate': 3.630952380952381e-05, 'epoch': 0.64}\n",
      "{'loss': 2.6416, 'learning_rate': 3.6011904761904765e-05, 'epoch': 0.64}\n",
      "{'loss': 2.311, 'learning_rate': 3.571428571428572e-05, 'epoch': 0.64}\n",
      "{'loss': 3.1226, 'learning_rate': 3.541666666666667e-05, 'epoch': 0.65}\n",
      "{'loss': 1.0553, 'learning_rate': 3.511904761904762e-05, 'epoch': 0.65}\n",
      "{'loss': 2.3045, 'learning_rate': 3.4821428571428574e-05, 'epoch': 0.65}\n",
      "{'loss': 2.0341, 'learning_rate': 3.4523809523809526e-05, 'epoch': 0.65}\n",
      "{'loss': 2.1353, 'learning_rate': 3.422619047619048e-05, 'epoch': 0.66}\n",
      "{'loss': 2.0072, 'learning_rate': 3.392857142857143e-05, 'epoch': 0.66}\n",
      "{'loss': 2.3231, 'learning_rate': 3.363095238095238e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0557, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.67}\n",
      "{'loss': 3.7452, 'learning_rate': 3.303571428571429e-05, 'epoch': 0.67}\n",
      "{'loss': 2.1374, 'learning_rate': 3.273809523809524e-05, 'epoch': 0.67}\n",
      "{'loss': 3.2998, 'learning_rate': 3.244047619047619e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9373, 'learning_rate': 3.2142857142857144e-05, 'epoch': 0.68}\n",
      "{'loss': 2.9502, 'learning_rate': 3.1845238095238096e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9943, 'learning_rate': 3.154761904761905e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7452, 'learning_rate': 3.125e-05, 'epoch': 0.69}\n",
      "{'loss': 3.656, 'learning_rate': 3.095238095238095e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9075, 'learning_rate': 3.0654761904761905e-05, 'epoch': 0.69}\n",
      "{'loss': 1.0953, 'learning_rate': 3.0357142857142857e-05, 'epoch': 0.7}\n",
      "{'loss': 2.46, 'learning_rate': 3.005952380952381e-05, 'epoch': 0.7}\n",
      "{'loss': 2.2805, 'learning_rate': 2.9761904761904762e-05, 'epoch': 0.7}\n",
      "{'loss': 3.037, 'learning_rate': 2.9464285714285718e-05, 'epoch': 0.71}\n",
      "{'loss': 0.9454, 'learning_rate': 2.916666666666667e-05, 'epoch': 0.71}\n",
      "{'loss': 2.1047, 'learning_rate': 2.886904761904762e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9adf77cc094551a9dda2d56e03a9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.294858694076538, 'eval_runtime': 15.3193, 'eval_samples_per_second': 9.792, 'eval_steps_per_second': 9.792, 'epoch': 0.71}\n",
      "{'loss': 2.389, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.71}\n",
      "{'loss': 3.3006, 'learning_rate': 2.8273809523809523e-05, 'epoch': 0.72}\n",
      "{'loss': 0.057, 'learning_rate': 2.797619047619048e-05, 'epoch': 0.72}\n",
      "{'loss': 1.5753, 'learning_rate': 2.767857142857143e-05, 'epoch': 0.72}\n",
      "{'loss': 2.2566, 'learning_rate': 2.7380952380952383e-05, 'epoch': 0.73}\n",
      "{'loss': 1.4744, 'learning_rate': 2.7083333333333332e-05, 'epoch': 0.73}\n",
      "{'loss': 3.254, 'learning_rate': 2.6785714285714288e-05, 'epoch': 0.73}\n",
      "{'loss': 3.9938, 'learning_rate': 2.648809523809524e-05, 'epoch': 0.73}\n",
      "{'loss': 4.0109, 'learning_rate': 2.6190476190476192e-05, 'epoch': 0.74}\n",
      "{'loss': 1.5466, 'learning_rate': 2.5892857142857148e-05, 'epoch': 0.74}\n",
      "{'loss': 1.9034, 'learning_rate': 2.5595238095238093e-05, 'epoch': 0.74}\n",
      "{'loss': 2.343, 'learning_rate': 2.529761904761905e-05, 'epoch': 0.75}\n",
      "{'loss': 2.88, 'learning_rate': 2.5e-05, 'epoch': 0.75}\n",
      "{'loss': 3.1854, 'learning_rate': 2.4702380952380953e-05, 'epoch': 0.75}\n",
      "{'loss': 1.4988, 'learning_rate': 2.4404761904761906e-05, 'epoch': 0.76}\n",
      "{'loss': 2.5751, 'learning_rate': 2.4107142857142858e-05, 'epoch': 0.76}\n",
      "{'loss': 3.6636, 'learning_rate': 2.380952380952381e-05, 'epoch': 0.76}\n",
      "{'loss': 2.1865, 'learning_rate': 2.3511904761904762e-05, 'epoch': 0.76}\n",
      "{'loss': 2.4617, 'learning_rate': 2.3214285714285715e-05, 'epoch': 0.77}\n",
      "{'loss': 2.8989, 'learning_rate': 2.2916666666666667e-05, 'epoch': 0.77}\n",
      "{'loss': 1.6552, 'learning_rate': 2.261904761904762e-05, 'epoch': 0.77}\n",
      "{'loss': 2.1068, 'learning_rate': 2.2321428571428575e-05, 'epoch': 0.78}\n",
      "{'loss': 0.5958, 'learning_rate': 2.2023809523809524e-05, 'epoch': 0.78}\n",
      "{'loss': 2.7345, 'learning_rate': 2.172619047619048e-05, 'epoch': 0.78}\n",
      "{'loss': 3.3818, 'learning_rate': 2.1428571428571428e-05, 'epoch': 0.79}\n",
      "{'loss': 1.8566, 'learning_rate': 2.113095238095238e-05, 'epoch': 0.79}\n",
      "{'loss': 2.4224, 'learning_rate': 2.0833333333333336e-05, 'epoch': 0.79}\n",
      "{'loss': 0.9492, 'learning_rate': 2.0535714285714285e-05, 'epoch': 0.79}\n",
      "{'loss': 3.7543, 'learning_rate': 2.023809523809524e-05, 'epoch': 0.8}\n",
      "{'loss': 3.54, 'learning_rate': 1.9940476190476193e-05, 'epoch': 0.8}\n",
      "{'loss': 2.8327, 'learning_rate': 1.9642857142857145e-05, 'epoch': 0.8}\n",
      "{'loss': 1.989, 'learning_rate': 1.9345238095238097e-05, 'epoch': 0.81}\n",
      "{'loss': 2.5413, 'learning_rate': 1.9047619047619046e-05, 'epoch': 0.81}\n",
      "{'loss': 2.126, 'learning_rate': 1.8750000000000002e-05, 'epoch': 0.81}\n",
      "{'loss': 3.8485, 'learning_rate': 1.8452380952380954e-05, 'epoch': 0.81}\n",
      "{'loss': 2.8026, 'learning_rate': 1.8154761904761906e-05, 'epoch': 0.82}\n",
      "{'loss': 0.8368, 'learning_rate': 1.785714285714286e-05, 'epoch': 0.82}\n",
      "{'loss': 2.946, 'learning_rate': 1.755952380952381e-05, 'epoch': 0.82}\n",
      "{'loss': 3.1115, 'learning_rate': 1.7261904761904763e-05, 'epoch': 0.83}\n",
      "{'loss': 2.9615, 'learning_rate': 1.6964285714285715e-05, 'epoch': 0.83}\n",
      "{'loss': 3.5052, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.83}\n",
      "{'loss': 0.056, 'learning_rate': 1.636904761904762e-05, 'epoch': 0.84}\n",
      "{'loss': 2.5744, 'learning_rate': 1.6071428571428572e-05, 'epoch': 0.84}\n",
      "{'loss': 1.7571, 'learning_rate': 1.5773809523809524e-05, 'epoch': 0.84}\n",
      "{'loss': 2.9502, 'learning_rate': 1.5476190476190476e-05, 'epoch': 0.84}\n",
      "{'loss': 0.9157, 'learning_rate': 1.5178571428571429e-05, 'epoch': 0.85}\n",
      "{'loss': 1.8889, 'learning_rate': 1.4880952380952381e-05, 'epoch': 0.85}\n",
      "{'loss': 2.9292, 'learning_rate': 1.4583333333333335e-05, 'epoch': 0.85}\n",
      "{'loss': 1.4298, 'learning_rate': 1.4285714285714285e-05, 'epoch': 0.86}\n",
      "{'loss': 1.8215, 'learning_rate': 1.398809523809524e-05, 'epoch': 0.86}\n",
      "{'loss': 2.5009, 'learning_rate': 1.3690476190476192e-05, 'epoch': 0.86}\n",
      "{'loss': 0.9781, 'learning_rate': 1.3392857142857144e-05, 'epoch': 0.87}\n",
      "{'loss': 1.6515, 'learning_rate': 1.3095238095238096e-05, 'epoch': 0.87}\n",
      "{'loss': 3.3031, 'learning_rate': 1.2797619047619047e-05, 'epoch': 0.87}\n",
      "{'loss': 2.4827, 'learning_rate': 1.25e-05, 'epoch': 0.87}\n",
      "{'loss': 3.022, 'learning_rate': 1.2202380952380953e-05, 'epoch': 0.88}\n",
      "{'loss': 1.6317, 'learning_rate': 1.1904761904761905e-05, 'epoch': 0.88}\n",
      "{'loss': 1.6325, 'learning_rate': 1.1607142857142857e-05, 'epoch': 0.88}\n",
      "{'loss': 1.5138, 'learning_rate': 1.130952380952381e-05, 'epoch': 0.89}\n",
      "{'loss': 3.8307, 'learning_rate': 1.1011904761904762e-05, 'epoch': 0.89}\n",
      "{'loss': 1.8345, 'learning_rate': 1.0714285714285714e-05, 'epoch': 0.89}\n",
      "{'loss': 3.5403, 'learning_rate': 1.0416666666666668e-05, 'epoch': 0.89}\n",
      "{'loss': 2.5874, 'learning_rate': 1.011904761904762e-05, 'epoch': 0.9}\n",
      "{'loss': 0.883, 'learning_rate': 9.821428571428573e-06, 'epoch': 0.9}\n",
      "{'loss': 1.5215, 'learning_rate': 9.523809523809523e-06, 'epoch': 0.9}\n",
      "{'loss': 1.88, 'learning_rate': 9.226190476190477e-06, 'epoch': 0.91}\n",
      "{'loss': 2.7913, 'learning_rate': 8.92857142857143e-06, 'epoch': 0.91}\n",
      "{'loss': 3.1024, 'learning_rate': 8.630952380952381e-06, 'epoch': 0.91}\n",
      "{'loss': 2.7694, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.92}\n",
      "{'loss': 1.7477, 'learning_rate': 8.035714285714286e-06, 'epoch': 0.92}\n",
      "{'loss': 3.4474, 'learning_rate': 7.738095238095238e-06, 'epoch': 0.92}\n",
      "{'loss': 2.0816, 'learning_rate': 7.4404761904761905e-06, 'epoch': 0.92}\n",
      "{'loss': 3.1108, 'learning_rate': 7.142857142857143e-06, 'epoch': 0.93}\n",
      "{'loss': 1.7187, 'learning_rate': 6.845238095238096e-06, 'epoch': 0.93}\n",
      "{'loss': 2.9535, 'learning_rate': 6.547619047619048e-06, 'epoch': 0.93}\n",
      "{'loss': 1.8999, 'learning_rate': 6.25e-06, 'epoch': 0.94}\n",
      "{'loss': 3.2236, 'learning_rate': 5.9523809523809525e-06, 'epoch': 0.94}\n",
      "{'loss': 2.6426, 'learning_rate': 5.654761904761905e-06, 'epoch': 0.94}\n",
      "{'loss': 2.6962, 'learning_rate': 5.357142857142857e-06, 'epoch': 0.95}\n",
      "{'loss': 0.7689, 'learning_rate': 5.05952380952381e-06, 'epoch': 0.95}\n",
      "{'loss': 2.9862, 'learning_rate': 4.7619047619047615e-06, 'epoch': 0.95}\n",
      "{'loss': 1.4461, 'learning_rate': 4.464285714285715e-06, 'epoch': 0.95}\n",
      "{'loss': 1.6871, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.96}\n",
      "{'loss': 2.3285, 'learning_rate': 3.869047619047619e-06, 'epoch': 0.96}\n",
      "{'loss': 2.9702, 'learning_rate': 3.5714285714285714e-06, 'epoch': 0.96}\n",
      "{'loss': 2.5096, 'learning_rate': 3.273809523809524e-06, 'epoch': 0.97}\n",
      "{'loss': 3.7373, 'learning_rate': 2.9761904761904763e-06, 'epoch': 0.97}\n",
      "{'loss': 3.3193, 'learning_rate': 2.6785714285714285e-06, 'epoch': 0.97}\n",
      "{'loss': 2.2109, 'learning_rate': 2.3809523809523808e-06, 'epoch': 0.97}\n",
      "{'loss': 2.1129, 'learning_rate': 2.0833333333333334e-06, 'epoch': 0.98}\n",
      "{'loss': 2.8564, 'learning_rate': 1.7857142857142857e-06, 'epoch': 0.98}\n",
      "{'loss': 3.0706, 'learning_rate': 1.4880952380952381e-06, 'epoch': 0.98}\n",
      "{'loss': 2.8076, 'learning_rate': 1.1904761904761904e-06, 'epoch': 0.99}\n",
      "{'loss': 2.7174, 'learning_rate': 8.928571428571428e-07, 'epoch': 0.99}\n",
      "{'loss': 3.6362, 'learning_rate': 5.952380952380952e-07, 'epoch': 0.99}\n",
      "{'loss': 2.7374, 'learning_rate': 2.976190476190476e-07, 'epoch': 1.0}\n",
      "{'loss': 3.5399, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'train_runtime': 644.5939, 'train_samples_per_second': 2.094, 'train_steps_per_second': 0.523, 'train_loss': 2.6397572294408205, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ee681efa9946c88bdc3f4ce2a65061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.0001, 'num_train_epochs': 1, 'per_device_train_batch_size': 1, 'optim': 'adafactor'}\n",
      "Best loss: 2.294858694076538\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoTokenizer\n",
    "from llama import BasicModelRunner\n",
    "from utilities import tokenize_and_split_data\n",
    "\n",
    "def find_best_hyperparameters():\n",
    "    model_name = \"EleutherAI/pythia-70m\"\n",
    "    use_hf = False\n",
    "\n",
    "    # Get the current directory\n",
    "    current_directory = os.getcwd()\n",
    "    # Join the folder path\n",
    "    folder_path = os.path.join(current_directory, \"content\")\n",
    "    dataset_name = \"ai-medical-chatbot_processed.jsonl\"\n",
    "    dataset_path = os.path.join(folder_path, dataset_name)\n",
    "\n",
    "    training_config = {\n",
    "        \"model\": {\n",
    "            \"pretrained_name\": model_name,\n",
    "            \"max_length\" : 2048\n",
    "        },\n",
    "        \"datasets\": {\n",
    "            \"use_hf\": use_hf,\n",
    "            \"path\": dataset_path\n",
    "        },\n",
    "        \"verbose\": True\n",
    "    }\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    train_dataset, test_dataset = tokenize_and_split_data(training_config, tokenizer)\n",
    "\n",
    "    best_hyperparameters = None\n",
    "    best_loss = float('inf')  # Initialize with a very high value\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "    hyperparameter_space = {\n",
    "        \"learning_rate\": [1e-5, 5e-5, 1e-4],\n",
    "        \"num_train_epochs\": [1, 2],\n",
    "        \"per_device_train_batch_size\": [1],\n",
    "        \"optim\": [\"adafactor\"],\n",
    "    }\n",
    "\n",
    "    # Define the number of iterations for random search\n",
    "    num_iterations = 1\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        # Randomly sample hyperparameters from the search space\n",
    "        hyperparameters = {\n",
    "            \"learning_rate\": random.choice(hyperparameter_space[\"learning_rate\"]),\n",
    "            \"num_train_epochs\": random.choice(hyperparameter_space[\"num_train_epochs\"]),\n",
    "            \"per_device_train_batch_size\": random.choice(hyperparameter_space[\"per_device_train_batch_size\"]),\n",
    "            \"optim\": random.choice(hyperparameter_space[\"optim\"]),\n",
    "        }\n",
    "\n",
    "        # Setup training_args with the sampled hyperparameters\n",
    "        training_args = TrainingArguments(\n",
    "            learning_rate=hyperparameters[\"learning_rate\"],\n",
    "            num_train_epochs=hyperparameters[\"num_train_epochs\"],\n",
    "            per_device_train_batch_size=hyperparameters[\"per_device_train_batch_size\"],\n",
    "            output_dir=\"./results\",  # Provide a dummy output directory\n",
    "            overwrite_output_dir=False,\n",
    "            disable_tqdm=False,\n",
    "            eval_steps=120,\n",
    "            save_steps=120,\n",
    "            warmup_steps=1,\n",
    "            per_device_eval_batch_size=1,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            logging_strategy=\"steps\",\n",
    "            logging_steps=1,\n",
    "            optim=hyperparameters[\"optim\"],\n",
    "            gradient_accumulation_steps=4,\n",
    "            gradient_checkpointing=False,\n",
    "            load_best_model_at_end=True,\n",
    "            save_total_limit=1,\n",
    "            metric_for_best_model=\"eval_loss\",\n",
    "            greater_is_better=False\n",
    "        )\n",
    "\n",
    "        # Ensure the model is on a CUDA device if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        base_model.to(device)\n",
    "\n",
    "        # Setup Trainer with the new hyperparameters\n",
    "        trainer = Trainer(\n",
    "            model=base_model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=test_dataset\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        training_output = trainer.train()\n",
    "\n",
    "        # Evaluate the model\n",
    "        eval_results = trainer.evaluate()\n",
    "\n",
    "        # Check if this set of hyperparameters gives better results\n",
    "        if eval_results[\"eval_loss\"] < best_loss:\n",
    "            best_loss = eval_results[\"eval_loss\"]\n",
    "            best_hyperparameters = hyperparameters\n",
    "\n",
    "    return best_hyperparameters, best_loss\n",
    "\n",
    "# Call the function to find the best hyperparameters\n",
    "best_hyperparameters, best_loss = find_best_hyperparameters()\n",
    "\n",
    "print(\"Best hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best loss:\", best_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 14:39:34,612 - DEBUG - utilities - Config: datasets.path: c:\\Blog\\How-to-Finetuning-Large-Language-Models\\content\\ai-medical-chatbot_processed.jsonl\n",
      "datasets.use_hf: false\n",
      "model.max_length: 2048\n",
      "model.pretrained_name: EleutherAI/pythia-70m\n",
      "verbose: true\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize False c:\\Blog\\How-to-Finetuning-Large-Language-Models\\content\\ai-medical-chatbot_processed.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 14:39:35,035 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-59ea57fe03c7d0e8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/dataset_info.json\n",
      "2024-04-08 14:39:35,046 - DEBUG - fsspec.local - open file: C:/Users/066226758/.cache/huggingface/datasets/json/default-59ea57fe03c7d0e8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/dataset_info.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6b9f91ec1e408680dca92faa031b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/337 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8075, 'learning_rate': 0.0001, 'epoch': 0.0}\n",
      "{'loss': 4.059, 'learning_rate': 9.970238095238096e-05, 'epoch': 0.01}\n",
      "{'loss': 4.3316, 'learning_rate': 9.940476190476191e-05, 'epoch': 0.01}\n",
      "{'loss': 4.3041, 'learning_rate': 9.910714285714286e-05, 'epoch': 0.01}\n",
      "{'loss': 4.5375, 'learning_rate': 9.880952380952381e-05, 'epoch': 0.01}\n",
      "{'loss': 4.4222, 'learning_rate': 9.851190476190477e-05, 'epoch': 0.02}\n",
      "{'loss': 2.9892, 'learning_rate': 9.821428571428572e-05, 'epoch': 0.02}\n",
      "{'loss': 3.8411, 'learning_rate': 9.791666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.2601, 'learning_rate': 9.761904761904762e-05, 'epoch': 0.03}\n",
      "{'loss': 3.6946, 'learning_rate': 9.732142857142858e-05, 'epoch': 0.03}\n",
      "{'loss': 4.0574, 'learning_rate': 9.702380952380953e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2695, 'learning_rate': 9.672619047619048e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4897, 'learning_rate': 9.642857142857143e-05, 'epoch': 0.04}\n",
      "{'loss': 3.1086, 'learning_rate': 9.613095238095238e-05, 'epoch': 0.04}\n",
      "{'loss': 3.9527, 'learning_rate': 9.583333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.653, 'learning_rate': 9.553571428571429e-05, 'epoch': 0.05}\n",
      "{'loss': 3.0544, 'learning_rate': 9.523809523809524e-05, 'epoch': 0.05}\n",
      "{'loss': 3.5362, 'learning_rate': 9.494047619047619e-05, 'epoch': 0.05}\n",
      "{'loss': 3.8524, 'learning_rate': 9.464285714285715e-05, 'epoch': 0.06}\n",
      "{'loss': 3.0338, 'learning_rate': 9.43452380952381e-05, 'epoch': 0.06}\n",
      "{'loss': 2.5479, 'learning_rate': 9.404761904761905e-05, 'epoch': 0.06}\n",
      "{'loss': 3.7884, 'learning_rate': 9.375e-05, 'epoch': 0.07}\n",
      "{'loss': 3.7715, 'learning_rate': 9.345238095238095e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7095, 'learning_rate': 9.31547619047619e-05, 'epoch': 0.07}\n",
      "{'loss': 2.4695, 'learning_rate': 9.285714285714286e-05, 'epoch': 0.07}\n",
      "{'loss': 3.816, 'learning_rate': 9.255952380952382e-05, 'epoch': 0.08}\n",
      "{'loss': 3.6493, 'learning_rate': 9.226190476190478e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9271, 'learning_rate': 9.196428571428572e-05, 'epoch': 0.08}\n",
      "{'loss': 2.2059, 'learning_rate': 9.166666666666667e-05, 'epoch': 0.09}\n",
      "{'loss': 4.2985, 'learning_rate': 9.136904761904762e-05, 'epoch': 0.09}\n",
      "{'loss': 3.5307, 'learning_rate': 9.107142857142857e-05, 'epoch': 0.09}\n",
      "{'loss': 1.5364, 'learning_rate': 9.077380952380952e-05, 'epoch': 0.09}\n",
      "{'loss': 4.4714, 'learning_rate': 9.047619047619048e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0176, 'learning_rate': 9.017857142857143e-05, 'epoch': 0.1}\n",
      "{'loss': 3.8341, 'learning_rate': 8.988095238095238e-05, 'epoch': 0.1}\n",
      "{'loss': 4.2339, 'learning_rate': 8.958333333333335e-05, 'epoch': 0.11}\n",
      "{'loss': 2.311, 'learning_rate': 8.92857142857143e-05, 'epoch': 0.11}\n",
      "{'loss': 2.2669, 'learning_rate': 8.898809523809524e-05, 'epoch': 0.11}\n",
      "{'loss': 2.9297, 'learning_rate': 8.869047619047619e-05, 'epoch': 0.12}\n",
      "{'loss': 2.9302, 'learning_rate': 8.839285714285714e-05, 'epoch': 0.12}\n",
      "{'loss': 1.622, 'learning_rate': 8.80952380952381e-05, 'epoch': 0.12}\n",
      "{'loss': 2.3528, 'learning_rate': 8.779761904761905e-05, 'epoch': 0.12}\n",
      "{'loss': 4.4973, 'learning_rate': 8.75e-05, 'epoch': 0.13}\n",
      "{'loss': 2.3177, 'learning_rate': 8.720238095238095e-05, 'epoch': 0.13}\n",
      "{'loss': 2.721, 'learning_rate': 8.690476190476192e-05, 'epoch': 0.13}\n",
      "{'loss': 3.7791, 'learning_rate': 8.660714285714287e-05, 'epoch': 0.14}\n",
      "{'loss': 3.4177, 'learning_rate': 8.630952380952382e-05, 'epoch': 0.14}\n",
      "{'loss': 4.8086, 'learning_rate': 8.601190476190477e-05, 'epoch': 0.14}\n",
      "{'loss': 3.1691, 'learning_rate': 8.571428571428571e-05, 'epoch': 0.15}\n",
      "{'loss': 1.2518, 'learning_rate': 8.541666666666666e-05, 'epoch': 0.15}\n",
      "{'loss': 3.2363, 'learning_rate': 8.511904761904762e-05, 'epoch': 0.15}\n",
      "{'loss': 3.5953, 'learning_rate': 8.482142857142857e-05, 'epoch': 0.15}\n",
      "{'loss': 3.7236, 'learning_rate': 8.452380952380952e-05, 'epoch': 0.16}\n",
      "{'loss': 3.6962, 'learning_rate': 8.422619047619049e-05, 'epoch': 0.16}\n",
      "{'loss': 3.184, 'learning_rate': 8.392857142857144e-05, 'epoch': 0.16}\n",
      "{'loss': 3.137, 'learning_rate': 8.363095238095239e-05, 'epoch': 0.17}\n",
      "{'loss': 2.8898, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.17}\n",
      "{'loss': 4.1857, 'learning_rate': 8.30357142857143e-05, 'epoch': 0.17}\n",
      "{'loss': 2.6372, 'learning_rate': 8.273809523809524e-05, 'epoch': 0.17}\n",
      "{'loss': 3.0279, 'learning_rate': 8.244047619047619e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0938, 'learning_rate': 8.214285714285714e-05, 'epoch': 0.18}\n",
      "{'loss': 4.7588, 'learning_rate': 8.184523809523809e-05, 'epoch': 0.18}\n",
      "{'loss': 2.7226, 'learning_rate': 8.154761904761904e-05, 'epoch': 0.19}\n",
      "{'loss': 1.0886, 'learning_rate': 8.125000000000001e-05, 'epoch': 0.19}\n",
      "{'loss': 4.31, 'learning_rate': 8.095238095238096e-05, 'epoch': 0.19}\n",
      "{'loss': 3.4932, 'learning_rate': 8.065476190476191e-05, 'epoch': 0.2}\n",
      "{'loss': 2.9497, 'learning_rate': 8.035714285714287e-05, 'epoch': 0.2}\n",
      "{'loss': 4.188, 'learning_rate': 8.005952380952382e-05, 'epoch': 0.2}\n",
      "{'loss': 4.4532, 'learning_rate': 7.976190476190477e-05, 'epoch': 0.2}\n",
      "{'loss': 2.6632, 'learning_rate': 7.946428571428571e-05, 'epoch': 0.21}\n",
      "{'loss': 2.5389, 'learning_rate': 7.916666666666666e-05, 'epoch': 0.21}\n",
      "{'loss': 3.7943, 'learning_rate': 7.886904761904761e-05, 'epoch': 0.21}\n",
      "{'loss': 1.7834, 'learning_rate': 7.857142857142858e-05, 'epoch': 0.22}\n",
      "{'loss': 2.6693, 'learning_rate': 7.827380952380953e-05, 'epoch': 0.22}\n",
      "{'loss': 3.7505, 'learning_rate': 7.797619047619048e-05, 'epoch': 0.22}\n",
      "{'loss': 4.486, 'learning_rate': 7.767857142857144e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9656, 'learning_rate': 7.738095238095239e-05, 'epoch': 0.23}\n",
      "{'loss': 3.7646, 'learning_rate': 7.708333333333334e-05, 'epoch': 0.23}\n",
      "{'loss': 3.1709, 'learning_rate': 7.67857142857143e-05, 'epoch': 0.23}\n",
      "{'loss': 3.6489, 'learning_rate': 7.648809523809523e-05, 'epoch': 0.24}\n",
      "{'loss': 2.1993, 'learning_rate': 7.619047619047618e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9343, 'learning_rate': 7.589285714285714e-05, 'epoch': 0.24}\n",
      "{'loss': 3.1276, 'learning_rate': 7.55952380952381e-05, 'epoch': 0.25}\n",
      "{'loss': 1.5995, 'learning_rate': 7.529761904761905e-05, 'epoch': 0.25}\n",
      "{'loss': 1.2421, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.25}\n",
      "{'loss': 2.0773, 'learning_rate': 7.470238095238096e-05, 'epoch': 0.25}\n",
      "{'loss': 2.9355, 'learning_rate': 7.440476190476191e-05, 'epoch': 0.26}\n",
      "{'loss': 1.2553, 'learning_rate': 7.410714285714286e-05, 'epoch': 0.26}\n",
      "{'loss': 3.1905, 'learning_rate': 7.380952380952382e-05, 'epoch': 0.26}\n",
      "{'loss': 4.4621, 'learning_rate': 7.351190476190477e-05, 'epoch': 0.27}\n",
      "{'loss': 2.9148, 'learning_rate': 7.321428571428571e-05, 'epoch': 0.27}\n",
      "{'loss': 4.0989, 'learning_rate': 7.291666666666667e-05, 'epoch': 0.27}\n",
      "{'loss': 4.2069, 'learning_rate': 7.261904761904762e-05, 'epoch': 0.28}\n",
      "{'loss': 2.3145, 'learning_rate': 7.232142857142858e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8878, 'learning_rate': 7.202380952380953e-05, 'epoch': 0.28}\n",
      "{'loss': 3.022, 'learning_rate': 7.172619047619048e-05, 'epoch': 0.28}\n",
      "{'loss': 2.7159, 'learning_rate': 7.142857142857143e-05, 'epoch': 0.29}\n",
      "{'loss': 3.44, 'learning_rate': 7.113095238095239e-05, 'epoch': 0.29}\n",
      "{'loss': 2.5589, 'learning_rate': 7.083333333333334e-05, 'epoch': 0.29}\n",
      "{'loss': 1.146, 'learning_rate': 7.053571428571429e-05, 'epoch': 0.3}\n",
      "{'loss': 2.4963, 'learning_rate': 7.023809523809524e-05, 'epoch': 0.3}\n",
      "{'loss': 2.133, 'learning_rate': 6.99404761904762e-05, 'epoch': 0.3}\n",
      "{'loss': 1.3393, 'learning_rate': 6.964285714285715e-05, 'epoch': 0.31}\n",
      "{'loss': 3.4953, 'learning_rate': 6.93452380952381e-05, 'epoch': 0.31}\n",
      "{'loss': 3.0783, 'learning_rate': 6.904761904761905e-05, 'epoch': 0.31}\n",
      "{'loss': 3.1287, 'learning_rate': 6.875e-05, 'epoch': 0.31}\n",
      "{'loss': 1.7299, 'learning_rate': 6.845238095238096e-05, 'epoch': 0.32}\n",
      "{'loss': 2.9015, 'learning_rate': 6.815476190476191e-05, 'epoch': 0.32}\n",
      "{'loss': 2.2668, 'learning_rate': 6.785714285714286e-05, 'epoch': 0.32}\n",
      "{'loss': 3.0753, 'learning_rate': 6.755952380952381e-05, 'epoch': 0.33}\n",
      "{'loss': 2.9426, 'learning_rate': 6.726190476190477e-05, 'epoch': 0.33}\n",
      "{'loss': 3.3276, 'learning_rate': 6.696428571428572e-05, 'epoch': 0.33}\n",
      "{'loss': 2.9622, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9963, 'learning_rate': 6.636904761904762e-05, 'epoch': 0.34}\n",
      "{'loss': 3.1405, 'learning_rate': 6.607142857142857e-05, 'epoch': 0.34}\n",
      "{'loss': 3.4358, 'learning_rate': 6.577380952380953e-05, 'epoch': 0.34}\n",
      "{'loss': 2.4059, 'learning_rate': 6.547619047619048e-05, 'epoch': 0.35}\n",
      "{'loss': 2.6074, 'learning_rate': 6.517857142857143e-05, 'epoch': 0.35}\n",
      "{'loss': 2.4823, 'learning_rate': 6.488095238095238e-05, 'epoch': 0.35}\n",
      "{'loss': 2.2915, 'learning_rate': 6.458333333333334e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16be1822db7f4e31a684ba48af1fc7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.450745105743408, 'eval_runtime': 14.0724, 'eval_samples_per_second': 10.659, 'eval_steps_per_second': 10.659, 'epoch': 0.36}\n",
      "{'loss': 1.1962, 'learning_rate': 6.428571428571429e-05, 'epoch': 0.36}\n",
      "{'loss': 3.2902, 'learning_rate': 6.398809523809524e-05, 'epoch': 0.36}\n",
      "{'loss': 3.2178, 'learning_rate': 6.369047619047619e-05, 'epoch': 0.36}\n",
      "{'loss': 1.91, 'learning_rate': 6.339285714285714e-05, 'epoch': 0.37}\n",
      "{'loss': 3.9891, 'learning_rate': 6.30952380952381e-05, 'epoch': 0.37}\n",
      "{'loss': 1.1567, 'learning_rate': 6.279761904761905e-05, 'epoch': 0.37}\n",
      "{'loss': 2.0525, 'learning_rate': 6.25e-05, 'epoch': 0.38}\n",
      "{'loss': 1.478, 'learning_rate': 6.220238095238095e-05, 'epoch': 0.38}\n",
      "{'loss': 1.983, 'learning_rate': 6.19047619047619e-05, 'epoch': 0.38}\n",
      "{'loss': 2.5472, 'learning_rate': 6.160714285714286e-05, 'epoch': 0.39}\n",
      "{'loss': 2.8977, 'learning_rate': 6.130952380952381e-05, 'epoch': 0.39}\n",
      "{'loss': 3.6254, 'learning_rate': 6.101190476190477e-05, 'epoch': 0.39}\n",
      "{'loss': 2.8704, 'learning_rate': 6.0714285714285715e-05, 'epoch': 0.39}\n",
      "{'loss': 3.0588, 'learning_rate': 6.041666666666667e-05, 'epoch': 0.4}\n",
      "{'loss': 3.134, 'learning_rate': 6.011904761904762e-05, 'epoch': 0.4}\n",
      "{'loss': 3.4182, 'learning_rate': 5.982142857142857e-05, 'epoch': 0.4}\n",
      "{'loss': 3.2685, 'learning_rate': 5.9523809523809524e-05, 'epoch': 0.41}\n",
      "{'loss': 1.0611, 'learning_rate': 5.922619047619048e-05, 'epoch': 0.41}\n",
      "{'loss': 2.9135, 'learning_rate': 5.8928571428571435e-05, 'epoch': 0.41}\n",
      "{'loss': 4.2441, 'learning_rate': 5.863095238095239e-05, 'epoch': 0.41}\n",
      "{'loss': 1.1013, 'learning_rate': 5.833333333333334e-05, 'epoch': 0.42}\n",
      "{'loss': 0.6941, 'learning_rate': 5.803571428571429e-05, 'epoch': 0.42}\n",
      "{'loss': 1.994, 'learning_rate': 5.773809523809524e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9693, 'learning_rate': 5.744047619047619e-05, 'epoch': 0.43}\n",
      "{'loss': 2.3848, 'learning_rate': 5.714285714285714e-05, 'epoch': 0.43}\n",
      "{'loss': 3.221, 'learning_rate': 5.6845238095238094e-05, 'epoch': 0.43}\n",
      "{'loss': 1.557, 'learning_rate': 5.6547619047619046e-05, 'epoch': 0.44}\n",
      "{'loss': 3.066, 'learning_rate': 5.6250000000000005e-05, 'epoch': 0.44}\n",
      "{'loss': 4.464, 'learning_rate': 5.595238095238096e-05, 'epoch': 0.44}\n",
      "{'loss': 3.0789, 'learning_rate': 5.565476190476191e-05, 'epoch': 0.44}\n",
      "{'loss': 1.1597, 'learning_rate': 5.535714285714286e-05, 'epoch': 0.45}\n",
      "{'loss': 1.6923, 'learning_rate': 5.5059523809523814e-05, 'epoch': 0.45}\n",
      "{'loss': 2.2225, 'learning_rate': 5.4761904761904766e-05, 'epoch': 0.45}\n",
      "{'loss': 2.0865, 'learning_rate': 5.446428571428571e-05, 'epoch': 0.46}\n",
      "{'loss': 1.53, 'learning_rate': 5.4166666666666664e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9062, 'learning_rate': 5.3869047619047616e-05, 'epoch': 0.46}\n",
      "{'loss': 2.6273, 'learning_rate': 5.3571428571428575e-05, 'epoch': 0.47}\n",
      "{'loss': 0.8642, 'learning_rate': 5.327380952380953e-05, 'epoch': 0.47}\n",
      "{'loss': 3.0149, 'learning_rate': 5.297619047619048e-05, 'epoch': 0.47}\n",
      "{'loss': 0.532, 'learning_rate': 5.267857142857143e-05, 'epoch': 0.47}\n",
      "{'loss': 3.6132, 'learning_rate': 5.2380952380952384e-05, 'epoch': 0.48}\n",
      "{'loss': 2.9829, 'learning_rate': 5.208333333333334e-05, 'epoch': 0.48}\n",
      "{'loss': 4.49, 'learning_rate': 5.1785714285714296e-05, 'epoch': 0.48}\n",
      "{'loss': 0.9709, 'learning_rate': 5.1488095238095234e-05, 'epoch': 0.49}\n",
      "{'loss': 0.96, 'learning_rate': 5.119047619047619e-05, 'epoch': 0.49}\n",
      "{'loss': 1.0361, 'learning_rate': 5.089285714285714e-05, 'epoch': 0.49}\n",
      "{'loss': 1.999, 'learning_rate': 5.05952380952381e-05, 'epoch': 0.49}\n",
      "{'loss': 1.6411, 'learning_rate': 5.029761904761905e-05, 'epoch': 0.5}\n",
      "{'loss': 2.447, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
      "{'loss': 2.9662, 'learning_rate': 4.9702380952380955e-05, 'epoch': 0.5}\n",
      "{'loss': 1.4238, 'learning_rate': 4.940476190476191e-05, 'epoch': 0.51}\n",
      "{'loss': 3.3438, 'learning_rate': 4.910714285714286e-05, 'epoch': 0.51}\n",
      "{'loss': 4.0447, 'learning_rate': 4.880952380952381e-05, 'epoch': 0.51}\n",
      "{'loss': 2.8844, 'learning_rate': 4.8511904761904764e-05, 'epoch': 0.52}\n",
      "{'loss': 2.1023, 'learning_rate': 4.8214285714285716e-05, 'epoch': 0.52}\n",
      "{'loss': 2.4102, 'learning_rate': 4.791666666666667e-05, 'epoch': 0.52}\n",
      "{'loss': 2.2601, 'learning_rate': 4.761904761904762e-05, 'epoch': 0.52}\n",
      "{'loss': 1.4527, 'learning_rate': 4.732142857142857e-05, 'epoch': 0.53}\n",
      "{'loss': 2.9943, 'learning_rate': 4.7023809523809525e-05, 'epoch': 0.53}\n",
      "{'loss': 2.3954, 'learning_rate': 4.672619047619048e-05, 'epoch': 0.53}\n",
      "{'loss': 1.0909, 'learning_rate': 4.642857142857143e-05, 'epoch': 0.54}\n",
      "{'loss': 2.3696, 'learning_rate': 4.613095238095239e-05, 'epoch': 0.54}\n",
      "{'loss': 2.8584, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.54}\n",
      "{'loss': 2.8918, 'learning_rate': 4.5535714285714286e-05, 'epoch': 0.55}\n",
      "{'loss': 0.63, 'learning_rate': 4.523809523809524e-05, 'epoch': 0.55}\n",
      "{'loss': 0.063, 'learning_rate': 4.494047619047619e-05, 'epoch': 0.55}\n",
      "{'loss': 1.1509, 'learning_rate': 4.464285714285715e-05, 'epoch': 0.55}\n",
      "{'loss': 3.059, 'learning_rate': 4.4345238095238095e-05, 'epoch': 0.56}\n",
      "{'loss': 2.9327, 'learning_rate': 4.404761904761905e-05, 'epoch': 0.56}\n",
      "{'loss': 4.1787, 'learning_rate': 4.375e-05, 'epoch': 0.56}\n",
      "{'loss': 2.5275, 'learning_rate': 4.345238095238096e-05, 'epoch': 0.57}\n",
      "{'loss': 2.2834, 'learning_rate': 4.315476190476191e-05, 'epoch': 0.57}\n",
      "{'loss': 0.9427, 'learning_rate': 4.2857142857142856e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8914, 'learning_rate': 4.255952380952381e-05, 'epoch': 0.57}\n",
      "{'loss': 1.1028, 'learning_rate': 4.226190476190476e-05, 'epoch': 0.58}\n",
      "{'loss': 2.3476, 'learning_rate': 4.196428571428572e-05, 'epoch': 0.58}\n",
      "{'loss': 3.8563, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.58}\n",
      "{'loss': 1.4443, 'learning_rate': 4.136904761904762e-05, 'epoch': 0.59}\n",
      "{'loss': 3.6124, 'learning_rate': 4.107142857142857e-05, 'epoch': 0.59}\n",
      "{'loss': 3.2031, 'learning_rate': 4.077380952380952e-05, 'epoch': 0.59}\n",
      "{'loss': 1.9182, 'learning_rate': 4.047619047619048e-05, 'epoch': 0.6}\n",
      "{'loss': 2.2322, 'learning_rate': 4.017857142857143e-05, 'epoch': 0.6}\n",
      "{'loss': 2.337, 'learning_rate': 3.9880952380952386e-05, 'epoch': 0.6}\n",
      "{'loss': 4.0762, 'learning_rate': 3.958333333333333e-05, 'epoch': 0.6}\n",
      "{'loss': 3.2307, 'learning_rate': 3.928571428571429e-05, 'epoch': 0.61}\n",
      "{'loss': 2.036, 'learning_rate': 3.898809523809524e-05, 'epoch': 0.61}\n",
      "{'loss': 3.1389, 'learning_rate': 3.8690476190476195e-05, 'epoch': 0.61}\n",
      "{'loss': 3.0011, 'learning_rate': 3.839285714285715e-05, 'epoch': 0.62}\n",
      "{'loss': 2.8924, 'learning_rate': 3.809523809523809e-05, 'epoch': 0.62}\n",
      "{'loss': 2.8468, 'learning_rate': 3.779761904761905e-05, 'epoch': 0.62}\n",
      "{'loss': 2.8247, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.63}\n",
      "{'loss': 2.5426, 'learning_rate': 3.7202380952380956e-05, 'epoch': 0.63}\n",
      "{'loss': 2.2849, 'learning_rate': 3.690476190476191e-05, 'epoch': 0.63}\n",
      "{'loss': 2.6075, 'learning_rate': 3.6607142857142853e-05, 'epoch': 0.63}\n",
      "{'loss': 3.1334, 'learning_rate': 3.630952380952381e-05, 'epoch': 0.64}\n",
      "{'loss': 2.6163, 'learning_rate': 3.6011904761904765e-05, 'epoch': 0.64}\n",
      "{'loss': 2.2922, 'learning_rate': 3.571428571428572e-05, 'epoch': 0.64}\n",
      "{'loss': 3.1519, 'learning_rate': 3.541666666666667e-05, 'epoch': 0.65}\n",
      "{'loss': 1.0083, 'learning_rate': 3.511904761904762e-05, 'epoch': 0.65}\n",
      "{'loss': 2.3043, 'learning_rate': 3.4821428571428574e-05, 'epoch': 0.65}\n",
      "{'loss': 2.0248, 'learning_rate': 3.4523809523809526e-05, 'epoch': 0.65}\n",
      "{'loss': 2.0859, 'learning_rate': 3.422619047619048e-05, 'epoch': 0.66}\n",
      "{'loss': 1.9318, 'learning_rate': 3.392857142857143e-05, 'epoch': 0.66}\n",
      "{'loss': 2.4145, 'learning_rate': 3.363095238095238e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0654, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.67}\n",
      "{'loss': 3.7082, 'learning_rate': 3.303571428571429e-05, 'epoch': 0.67}\n",
      "{'loss': 2.1467, 'learning_rate': 3.273809523809524e-05, 'epoch': 0.67}\n",
      "{'loss': 3.287, 'learning_rate': 3.244047619047619e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8806, 'learning_rate': 3.2142857142857144e-05, 'epoch': 0.68}\n",
      "{'loss': 2.8821, 'learning_rate': 3.1845238095238096e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9828, 'learning_rate': 3.154761904761905e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7173, 'learning_rate': 3.125e-05, 'epoch': 0.69}\n",
      "{'loss': 3.5619, 'learning_rate': 3.095238095238095e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9008, 'learning_rate': 3.0654761904761905e-05, 'epoch': 0.69}\n",
      "{'loss': 1.0621, 'learning_rate': 3.0357142857142857e-05, 'epoch': 0.7}\n",
      "{'loss': 2.4246, 'learning_rate': 3.005952380952381e-05, 'epoch': 0.7}\n",
      "{'loss': 2.2693, 'learning_rate': 2.9761904761904762e-05, 'epoch': 0.7}\n",
      "{'loss': 2.9869, 'learning_rate': 2.9464285714285718e-05, 'epoch': 0.71}\n",
      "{'loss': 0.9577, 'learning_rate': 2.916666666666667e-05, 'epoch': 0.71}\n",
      "{'loss': 2.1067, 'learning_rate': 2.886904761904762e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d9f730ac8545e0a2b6e539e1e99ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2615952491760254, 'eval_runtime': 15.2472, 'eval_samples_per_second': 9.838, 'eval_steps_per_second': 9.838, 'epoch': 0.71}\n",
      "{'loss': 2.3499, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.71}\n",
      "{'loss': 3.2465, 'learning_rate': 2.8273809523809523e-05, 'epoch': 0.72}\n",
      "{'loss': 0.063, 'learning_rate': 2.797619047619048e-05, 'epoch': 0.72}\n",
      "{'loss': 1.5921, 'learning_rate': 2.767857142857143e-05, 'epoch': 0.72}\n",
      "{'loss': 2.2241, 'learning_rate': 2.7380952380952383e-05, 'epoch': 0.73}\n",
      "{'loss': 1.4195, 'learning_rate': 2.7083333333333332e-05, 'epoch': 0.73}\n",
      "{'loss': 3.2727, 'learning_rate': 2.6785714285714288e-05, 'epoch': 0.73}\n",
      "{'loss': 3.9809, 'learning_rate': 2.648809523809524e-05, 'epoch': 0.73}\n",
      "{'loss': 3.9511, 'learning_rate': 2.6190476190476192e-05, 'epoch': 0.74}\n",
      "{'loss': 1.4922, 'learning_rate': 2.5892857142857148e-05, 'epoch': 0.74}\n",
      "{'loss': 1.8645, 'learning_rate': 2.5595238095238093e-05, 'epoch': 0.74}\n",
      "{'loss': 2.3195, 'learning_rate': 2.529761904761905e-05, 'epoch': 0.75}\n",
      "{'loss': 2.8165, 'learning_rate': 2.5e-05, 'epoch': 0.75}\n",
      "{'loss': 3.14, 'learning_rate': 2.4702380952380953e-05, 'epoch': 0.75}\n",
      "{'loss': 1.5448, 'learning_rate': 2.4404761904761906e-05, 'epoch': 0.76}\n",
      "{'loss': 2.5157, 'learning_rate': 2.4107142857142858e-05, 'epoch': 0.76}\n",
      "{'loss': 3.536, 'learning_rate': 2.380952380952381e-05, 'epoch': 0.76}\n",
      "{'loss': 2.1132, 'learning_rate': 2.3511904761904762e-05, 'epoch': 0.76}\n",
      "{'loss': 2.3869, 'learning_rate': 2.3214285714285715e-05, 'epoch': 0.77}\n",
      "{'loss': 2.8825, 'learning_rate': 2.2916666666666667e-05, 'epoch': 0.77}\n",
      "{'loss': 1.5769, 'learning_rate': 2.261904761904762e-05, 'epoch': 0.77}\n",
      "{'loss': 2.0858, 'learning_rate': 2.2321428571428575e-05, 'epoch': 0.78}\n",
      "{'loss': 0.5871, 'learning_rate': 2.2023809523809524e-05, 'epoch': 0.78}\n",
      "{'loss': 2.6861, 'learning_rate': 2.172619047619048e-05, 'epoch': 0.78}\n",
      "{'loss': 3.2946, 'learning_rate': 2.1428571428571428e-05, 'epoch': 0.79}\n",
      "{'loss': 1.7948, 'learning_rate': 2.113095238095238e-05, 'epoch': 0.79}\n",
      "{'loss': 2.3542, 'learning_rate': 2.0833333333333336e-05, 'epoch': 0.79}\n",
      "{'loss': 0.9471, 'learning_rate': 2.0535714285714285e-05, 'epoch': 0.79}\n",
      "{'loss': 3.7198, 'learning_rate': 2.023809523809524e-05, 'epoch': 0.8}\n",
      "{'loss': 3.4466, 'learning_rate': 1.9940476190476193e-05, 'epoch': 0.8}\n",
      "{'loss': 2.7587, 'learning_rate': 1.9642857142857145e-05, 'epoch': 0.8}\n",
      "{'loss': 1.9326, 'learning_rate': 1.9345238095238097e-05, 'epoch': 0.81}\n",
      "{'loss': 2.5021, 'learning_rate': 1.9047619047619046e-05, 'epoch': 0.81}\n",
      "{'loss': 2.0889, 'learning_rate': 1.8750000000000002e-05, 'epoch': 0.81}\n",
      "{'loss': 3.8261, 'learning_rate': 1.8452380952380954e-05, 'epoch': 0.81}\n",
      "{'loss': 2.7241, 'learning_rate': 1.8154761904761906e-05, 'epoch': 0.82}\n",
      "{'loss': 0.827, 'learning_rate': 1.785714285714286e-05, 'epoch': 0.82}\n",
      "{'loss': 2.8812, 'learning_rate': 1.755952380952381e-05, 'epoch': 0.82}\n",
      "{'loss': 3.0069, 'learning_rate': 1.7261904761904763e-05, 'epoch': 0.83}\n",
      "{'loss': 2.9049, 'learning_rate': 1.6964285714285715e-05, 'epoch': 0.83}\n",
      "{'loss': 3.511, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.83}\n",
      "{'loss': 0.0547, 'learning_rate': 1.636904761904762e-05, 'epoch': 0.84}\n",
      "{'loss': 2.5425, 'learning_rate': 1.6071428571428572e-05, 'epoch': 0.84}\n",
      "{'loss': 1.7428, 'learning_rate': 1.5773809523809524e-05, 'epoch': 0.84}\n",
      "{'loss': 2.8428, 'learning_rate': 1.5476190476190476e-05, 'epoch': 0.84}\n",
      "{'loss': 0.9012, 'learning_rate': 1.5178571428571429e-05, 'epoch': 0.85}\n",
      "{'loss': 1.8845, 'learning_rate': 1.4880952380952381e-05, 'epoch': 0.85}\n",
      "{'loss': 2.8484, 'learning_rate': 1.4583333333333335e-05, 'epoch': 0.85}\n",
      "{'loss': 1.4428, 'learning_rate': 1.4285714285714285e-05, 'epoch': 0.86}\n",
      "{'loss': 1.7942, 'learning_rate': 1.398809523809524e-05, 'epoch': 0.86}\n",
      "{'loss': 2.4607, 'learning_rate': 1.3690476190476192e-05, 'epoch': 0.86}\n",
      "{'loss': 0.9595, 'learning_rate': 1.3392857142857144e-05, 'epoch': 0.87}\n",
      "{'loss': 1.6499, 'learning_rate': 1.3095238095238096e-05, 'epoch': 0.87}\n",
      "{'loss': 3.2441, 'learning_rate': 1.2797619047619047e-05, 'epoch': 0.87}\n",
      "{'loss': 2.4399, 'learning_rate': 1.25e-05, 'epoch': 0.87}\n",
      "{'loss': 2.9808, 'learning_rate': 1.2202380952380953e-05, 'epoch': 0.88}\n",
      "{'loss': 1.6255, 'learning_rate': 1.1904761904761905e-05, 'epoch': 0.88}\n",
      "{'loss': 1.6063, 'learning_rate': 1.1607142857142857e-05, 'epoch': 0.88}\n",
      "{'loss': 1.5274, 'learning_rate': 1.130952380952381e-05, 'epoch': 0.89}\n",
      "{'loss': 3.7958, 'learning_rate': 1.1011904761904762e-05, 'epoch': 0.89}\n",
      "{'loss': 1.8018, 'learning_rate': 1.0714285714285714e-05, 'epoch': 0.89}\n",
      "{'loss': 3.5604, 'learning_rate': 1.0416666666666668e-05, 'epoch': 0.89}\n",
      "{'loss': 2.5789, 'learning_rate': 1.011904761904762e-05, 'epoch': 0.9}\n",
      "{'loss': 0.8715, 'learning_rate': 9.821428571428573e-06, 'epoch': 0.9}\n",
      "{'loss': 1.5101, 'learning_rate': 9.523809523809523e-06, 'epoch': 0.9}\n",
      "{'loss': 1.8274, 'learning_rate': 9.226190476190477e-06, 'epoch': 0.91}\n",
      "{'loss': 2.7882, 'learning_rate': 8.92857142857143e-06, 'epoch': 0.91}\n",
      "{'loss': 3.0966, 'learning_rate': 8.630952380952381e-06, 'epoch': 0.91}\n",
      "{'loss': 2.6951, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.92}\n",
      "{'loss': 1.7253, 'learning_rate': 8.035714285714286e-06, 'epoch': 0.92}\n",
      "{'loss': 3.3867, 'learning_rate': 7.738095238095238e-06, 'epoch': 0.92}\n",
      "{'loss': 2.0573, 'learning_rate': 7.4404761904761905e-06, 'epoch': 0.92}\n",
      "{'loss': 3.052, 'learning_rate': 7.142857142857143e-06, 'epoch': 0.93}\n",
      "{'loss': 1.7753, 'learning_rate': 6.845238095238096e-06, 'epoch': 0.93}\n",
      "{'loss': 2.8566, 'learning_rate': 6.547619047619048e-06, 'epoch': 0.93}\n",
      "{'loss': 1.9093, 'learning_rate': 6.25e-06, 'epoch': 0.94}\n",
      "{'loss': 3.1833, 'learning_rate': 5.9523809523809525e-06, 'epoch': 0.94}\n",
      "{'loss': 2.6404, 'learning_rate': 5.654761904761905e-06, 'epoch': 0.94}\n",
      "{'loss': 2.6646, 'learning_rate': 5.357142857142857e-06, 'epoch': 0.95}\n",
      "{'loss': 0.7433, 'learning_rate': 5.05952380952381e-06, 'epoch': 0.95}\n",
      "{'loss': 2.9928, 'learning_rate': 4.7619047619047615e-06, 'epoch': 0.95}\n",
      "{'loss': 1.4099, 'learning_rate': 4.464285714285715e-06, 'epoch': 0.95}\n",
      "{'loss': 1.6817, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.96}\n",
      "{'loss': 2.2451, 'learning_rate': 3.869047619047619e-06, 'epoch': 0.96}\n",
      "{'loss': 2.9363, 'learning_rate': 3.5714285714285714e-06, 'epoch': 0.96}\n",
      "{'loss': 2.4991, 'learning_rate': 3.273809523809524e-06, 'epoch': 0.97}\n",
      "{'loss': 3.6878, 'learning_rate': 2.9761904761904763e-06, 'epoch': 0.97}\n",
      "{'loss': 3.2988, 'learning_rate': 2.6785714285714285e-06, 'epoch': 0.97}\n",
      "{'loss': 2.2027, 'learning_rate': 2.3809523809523808e-06, 'epoch': 0.97}\n",
      "{'loss': 2.1068, 'learning_rate': 2.0833333333333334e-06, 'epoch': 0.98}\n",
      "{'loss': 2.8406, 'learning_rate': 1.7857142857142857e-06, 'epoch': 0.98}\n",
      "{'loss': 3.0032, 'learning_rate': 1.4880952380952381e-06, 'epoch': 0.98}\n",
      "{'loss': 2.7609, 'learning_rate': 1.1904761904761904e-06, 'epoch': 0.99}\n",
      "{'loss': 2.6185, 'learning_rate': 8.928571428571428e-07, 'epoch': 0.99}\n",
      "{'loss': 3.5884, 'learning_rate': 5.952380952380952e-07, 'epoch': 0.99}\n",
      "{'loss': 2.759, 'learning_rate': 2.976190476190476e-07, 'epoch': 1.0}\n",
      "{'loss': 3.5099, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'train_runtime': 616.7921, 'train_samples_per_second': 2.189, 'train_steps_per_second': 0.546, 'train_loss': 2.6148144501960595, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d73170af0414de9812ec979907e7c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a36c5e17642490091c804f4e94c985d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/337 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8119, 'learning_rate': 0.0001, 'epoch': 0.0}\n",
      "{'loss': 2.6053, 'learning_rate': 9.970238095238096e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7492, 'learning_rate': 9.940476190476191e-05, 'epoch': 0.01}\n",
      "{'loss': 3.1741, 'learning_rate': 9.910714285714286e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4395, 'learning_rate': 9.880952380952381e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3348, 'learning_rate': 9.851190476190477e-05, 'epoch': 0.02}\n",
      "{'loss': 1.605, 'learning_rate': 9.821428571428572e-05, 'epoch': 0.02}\n",
      "{'loss': 2.9279, 'learning_rate': 9.791666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 2.138, 'learning_rate': 9.761904761904762e-05, 'epoch': 0.03}\n",
      "{'loss': 2.0605, 'learning_rate': 9.732142857142858e-05, 'epoch': 0.03}\n",
      "{'loss': 2.708, 'learning_rate': 9.702380952380953e-05, 'epoch': 0.03}\n",
      "{'loss': 2.1713, 'learning_rate': 9.672619047619048e-05, 'epoch': 0.04}\n",
      "{'loss': 2.6467, 'learning_rate': 9.642857142857143e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0659, 'learning_rate': 9.613095238095238e-05, 'epoch': 0.04}\n",
      "{'loss': 3.1968, 'learning_rate': 9.583333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 2.826, 'learning_rate': 9.553571428571429e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9949, 'learning_rate': 9.523809523809524e-05, 'epoch': 0.05}\n",
      "{'loss': 2.7062, 'learning_rate': 9.494047619047619e-05, 'epoch': 0.05}\n",
      "{'loss': 3.0493, 'learning_rate': 9.464285714285715e-05, 'epoch': 0.06}\n",
      "{'loss': 2.4345, 'learning_rate': 9.43452380952381e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1853, 'learning_rate': 9.404761904761905e-05, 'epoch': 0.06}\n",
      "{'loss': 2.9444, 'learning_rate': 9.375e-05, 'epoch': 0.07}\n",
      "{'loss': 3.424, 'learning_rate': 9.345238095238095e-05, 'epoch': 0.07}\n",
      "{'loss': 1.157, 'learning_rate': 9.31547619047619e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9171, 'learning_rate': 9.285714285714286e-05, 'epoch': 0.07}\n",
      "{'loss': 3.037, 'learning_rate': 9.255952380952382e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2212, 'learning_rate': 9.226190476190478e-05, 'epoch': 0.08}\n",
      "{'loss': 0.9128, 'learning_rate': 9.196428571428572e-05, 'epoch': 0.08}\n",
      "{'loss': 1.735, 'learning_rate': 9.166666666666667e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3057, 'learning_rate': 9.136904761904762e-05, 'epoch': 0.09}\n",
      "{'loss': 3.0157, 'learning_rate': 9.107142857142857e-05, 'epoch': 0.09}\n",
      "{'loss': 0.8414, 'learning_rate': 9.077380952380952e-05, 'epoch': 0.09}\n",
      "{'loss': 3.697, 'learning_rate': 9.047619047619048e-05, 'epoch': 0.1}\n",
      "{'loss': 1.4816, 'learning_rate': 9.017857142857143e-05, 'epoch': 0.1}\n",
      "{'loss': 3.1136, 'learning_rate': 8.988095238095238e-05, 'epoch': 0.1}\n",
      "{'loss': 3.7473, 'learning_rate': 8.958333333333335e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8145, 'learning_rate': 8.92857142857143e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7177, 'learning_rate': 8.898809523809524e-05, 'epoch': 0.11}\n",
      "{'loss': 2.4153, 'learning_rate': 8.869047619047619e-05, 'epoch': 0.12}\n",
      "{'loss': 2.2223, 'learning_rate': 8.839285714285714e-05, 'epoch': 0.12}\n",
      "{'loss': 1.2935, 'learning_rate': 8.80952380952381e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8993, 'learning_rate': 8.779761904761905e-05, 'epoch': 0.12}\n",
      "{'loss': 3.841, 'learning_rate': 8.75e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7816, 'learning_rate': 8.720238095238095e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9309, 'learning_rate': 8.690476190476192e-05, 'epoch': 0.13}\n",
      "{'loss': 2.9553, 'learning_rate': 8.660714285714287e-05, 'epoch': 0.14}\n",
      "{'loss': 3.1203, 'learning_rate': 8.630952380952382e-05, 'epoch': 0.14}\n",
      "{'loss': 4.4742, 'learning_rate': 8.601190476190477e-05, 'epoch': 0.14}\n",
      "{'loss': 2.4101, 'learning_rate': 8.571428571428571e-05, 'epoch': 0.15}\n",
      "{'loss': 1.0208, 'learning_rate': 8.541666666666666e-05, 'epoch': 0.15}\n",
      "{'loss': 2.7583, 'learning_rate': 8.511904761904762e-05, 'epoch': 0.15}\n",
      "{'loss': 2.8793, 'learning_rate': 8.482142857142857e-05, 'epoch': 0.15}\n",
      "{'loss': 3.0419, 'learning_rate': 8.452380952380952e-05, 'epoch': 0.16}\n",
      "{'loss': 2.9348, 'learning_rate': 8.422619047619049e-05, 'epoch': 0.16}\n",
      "{'loss': 2.8418, 'learning_rate': 8.392857142857144e-05, 'epoch': 0.16}\n",
      "{'loss': 2.4946, 'learning_rate': 8.363095238095239e-05, 'epoch': 0.17}\n",
      "{'loss': 2.3118, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.17}\n",
      "{'loss': 3.3573, 'learning_rate': 8.30357142857143e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9264, 'learning_rate': 8.273809523809524e-05, 'epoch': 0.17}\n",
      "{'loss': 2.6107, 'learning_rate': 8.244047619047619e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0526, 'learning_rate': 8.214285714285714e-05, 'epoch': 0.18}\n",
      "{'loss': 3.7623, 'learning_rate': 8.184523809523809e-05, 'epoch': 0.18}\n",
      "{'loss': 2.3903, 'learning_rate': 8.154761904761904e-05, 'epoch': 0.19}\n",
      "{'loss': 0.8343, 'learning_rate': 8.125000000000001e-05, 'epoch': 0.19}\n",
      "{'loss': 3.2505, 'learning_rate': 8.095238095238096e-05, 'epoch': 0.19}\n",
      "{'loss': 2.9599, 'learning_rate': 8.065476190476191e-05, 'epoch': 0.2}\n",
      "{'loss': 2.4715, 'learning_rate': 8.035714285714287e-05, 'epoch': 0.2}\n",
      "{'loss': 3.6122, 'learning_rate': 8.005952380952382e-05, 'epoch': 0.2}\n",
      "{'loss': 3.9545, 'learning_rate': 7.976190476190477e-05, 'epoch': 0.2}\n",
      "{'loss': 2.2853, 'learning_rate': 7.946428571428571e-05, 'epoch': 0.21}\n",
      "{'loss': 2.1696, 'learning_rate': 7.916666666666666e-05, 'epoch': 0.21}\n",
      "{'loss': 3.2387, 'learning_rate': 7.886904761904761e-05, 'epoch': 0.21}\n",
      "{'loss': 1.2168, 'learning_rate': 7.857142857142858e-05, 'epoch': 0.22}\n",
      "{'loss': 2.1898, 'learning_rate': 7.827380952380953e-05, 'epoch': 0.22}\n",
      "{'loss': 3.2229, 'learning_rate': 7.797619047619048e-05, 'epoch': 0.22}\n",
      "{'loss': 3.9103, 'learning_rate': 7.767857142857144e-05, 'epoch': 0.23}\n",
      "{'loss': 1.5483, 'learning_rate': 7.738095238095239e-05, 'epoch': 0.23}\n",
      "{'loss': 3.2068, 'learning_rate': 7.708333333333334e-05, 'epoch': 0.23}\n",
      "{'loss': 2.5827, 'learning_rate': 7.67857142857143e-05, 'epoch': 0.23}\n",
      "{'loss': 3.1506, 'learning_rate': 7.648809523809523e-05, 'epoch': 0.24}\n",
      "{'loss': 1.7874, 'learning_rate': 7.619047619047618e-05, 'epoch': 0.24}\n",
      "{'loss': 1.5238, 'learning_rate': 7.589285714285714e-05, 'epoch': 0.24}\n",
      "{'loss': 2.6421, 'learning_rate': 7.55952380952381e-05, 'epoch': 0.25}\n",
      "{'loss': 1.1173, 'learning_rate': 7.529761904761905e-05, 'epoch': 0.25}\n",
      "{'loss': 0.9985, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.25}\n",
      "{'loss': 1.5943, 'learning_rate': 7.470238095238096e-05, 'epoch': 0.25}\n",
      "{'loss': 2.5535, 'learning_rate': 7.440476190476191e-05, 'epoch': 0.26}\n",
      "{'loss': 1.0647, 'learning_rate': 7.410714285714286e-05, 'epoch': 0.26}\n",
      "{'loss': 2.6897, 'learning_rate': 7.380952380952382e-05, 'epoch': 0.26}\n",
      "{'loss': 3.8194, 'learning_rate': 7.351190476190477e-05, 'epoch': 0.27}\n",
      "{'loss': 2.5221, 'learning_rate': 7.321428571428571e-05, 'epoch': 0.27}\n",
      "{'loss': 3.8494, 'learning_rate': 7.291666666666667e-05, 'epoch': 0.27}\n",
      "{'loss': 3.7638, 'learning_rate': 7.261904761904762e-05, 'epoch': 0.28}\n",
      "{'loss': 2.1494, 'learning_rate': 7.232142857142858e-05, 'epoch': 0.28}\n",
      "{'loss': 1.4646, 'learning_rate': 7.202380952380953e-05, 'epoch': 0.28}\n",
      "{'loss': 2.5154, 'learning_rate': 7.172619047619048e-05, 'epoch': 0.28}\n",
      "{'loss': 2.272, 'learning_rate': 7.142857142857143e-05, 'epoch': 0.29}\n",
      "{'loss': 3.1988, 'learning_rate': 7.113095238095239e-05, 'epoch': 0.29}\n",
      "{'loss': 2.2081, 'learning_rate': 7.083333333333334e-05, 'epoch': 0.29}\n",
      "{'loss': 0.8872, 'learning_rate': 7.053571428571429e-05, 'epoch': 0.3}\n",
      "{'loss': 2.2235, 'learning_rate': 7.023809523809524e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8446, 'learning_rate': 6.99404761904762e-05, 'epoch': 0.3}\n",
      "{'loss': 1.206, 'learning_rate': 6.964285714285715e-05, 'epoch': 0.31}\n",
      "{'loss': 2.8535, 'learning_rate': 6.93452380952381e-05, 'epoch': 0.31}\n",
      "{'loss': 2.9057, 'learning_rate': 6.904761904761905e-05, 'epoch': 0.31}\n",
      "{'loss': 2.7303, 'learning_rate': 6.875e-05, 'epoch': 0.31}\n",
      "{'loss': 1.4428, 'learning_rate': 6.845238095238096e-05, 'epoch': 0.32}\n",
      "{'loss': 2.3719, 'learning_rate': 6.815476190476191e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8294, 'learning_rate': 6.785714285714286e-05, 'epoch': 0.32}\n",
      "{'loss': 2.7922, 'learning_rate': 6.755952380952381e-05, 'epoch': 0.33}\n",
      "{'loss': 2.6328, 'learning_rate': 6.726190476190477e-05, 'epoch': 0.33}\n",
      "{'loss': 2.9943, 'learning_rate': 6.696428571428572e-05, 'epoch': 0.33}\n",
      "{'loss': 2.5475, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.33}\n",
      "{'loss': 1.5402, 'learning_rate': 6.636904761904762e-05, 'epoch': 0.34}\n",
      "{'loss': 2.7068, 'learning_rate': 6.607142857142857e-05, 'epoch': 0.34}\n",
      "{'loss': 3.0048, 'learning_rate': 6.577380952380953e-05, 'epoch': 0.34}\n",
      "{'loss': 2.2038, 'learning_rate': 6.547619047619048e-05, 'epoch': 0.35}\n",
      "{'loss': 2.1789, 'learning_rate': 6.517857142857143e-05, 'epoch': 0.35}\n",
      "{'loss': 2.0599, 'learning_rate': 6.488095238095238e-05, 'epoch': 0.35}\n",
      "{'loss': 2.037, 'learning_rate': 6.458333333333334e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc11c361163e475e9f0ccf8febac4d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6152780055999756, 'eval_runtime': 14.6861, 'eval_samples_per_second': 10.214, 'eval_steps_per_second': 10.214, 'epoch': 0.36}\n",
      "{'loss': 0.9748, 'learning_rate': 6.428571428571429e-05, 'epoch': 0.36}\n",
      "{'loss': 2.8658, 'learning_rate': 6.398809523809524e-05, 'epoch': 0.36}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to find the best hyperparameters with evaluation strategy as epoch\n",
    "best_hyperparameters, best_loss = find_best_hyperparameters(strategy=\"epoch\")\n",
    "print(\"Best hyperparameters (strategy=epoch):\", best_hyperparameters)\n",
    "print(\"Best loss (strategy=epoch):\", best_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
